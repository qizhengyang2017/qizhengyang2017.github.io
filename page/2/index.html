<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.4.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.4.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.4.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.4.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.4.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '6.4.0',
    sidebar: {"position":"left","display":"hide","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta property="og:type" content="website">
<meta property="og:title" content="Qizhengyang">
<meta property="og:url" content="https://qizhengyang2017.github.io/page/2/index.html">
<meta property="og:site_name" content="Qizhengyang">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Qizhengyang">






  <link rel="canonical" href="https://qizhengyang2017.github.io/page/2/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Qizhengyang</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Qizhengyang</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />Home</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />About</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />Tags</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />Archives</a>
  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />Search</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://qizhengyang2017.github.io/2019/02/26/JBrowse 安装和使用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qizhengyang">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/26/JBrowse 安装和使用/" itemprop="url">
                  JBrowse 安装和使用
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-26 16:05:41" itemprop="dateCreated datePublished" datetime="2019-02-26T16:05:41+08:00">2019-02-26</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-03-01 00:28:04" itemprop="dateModified" datetime="2019-03-01T00:28:04+08:00">2019-03-01</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>这件事情弄了我两天。查看处理错误信息占据了大部分时间。好在最后终于成功了。</p>
<p>感悟，对于技术文档不能完全照搬。中文的技术文档，主要的作用是了解，最后的实践一定要<strong>充分参考官方的英文文档。</strong></p>
<h2 id="基因浏览器介绍（入门）"><a href="#基因浏览器介绍（入门）" class="headerlink" title="基因浏览器介绍（入门）"></a>基因浏览器介绍（入门）</h2><p><a href="https://www.plob.org/article/11742.html" target="_blank" rel="noopener">https://www.plob.org/article/11742.html</a></p>
<blockquote>
<p>在日常数据处理和分析工作中，根据分析项目的不同我们会面对各种各样的文件，比如mapping得到的SAM或者BAM文件，在此基础上转化而来的记录各种（定量）信息的bedgraph文件、Wig文件或者tdf文件，亦或记录variant信息的VCF文件。以至于有一种比较调侃的说法，所谓<strong>“生物信息”</strong>就是整天和各种格式的文件打交道，转换来转换去。</p>
<p><strong>JBrowse</strong> 是今天要介绍的主角。它是<strong>GMOD</strong>开源项目的一部分，想了解这个开源项目可以查看它的官方网站<a href="http://gmod.org/wiki/Main_Page" target="_blank" rel="noopener">http://gmod.org/wiki/Main_Page</a></p>
<p>完全基于<strong>HTML5</strong>和<strong>Javascript</strong>构建的JBrowse通过<strong>AJAX</strong>技术实现了数据的异步加载，所以响应速度非常快。由于Javascript将大量的计算工作在前端完成，服务器端只需要向浏览器客户端发送静态文件，因此也极大程度减轻了服务器端的负担。</p>
<p>完全基于<strong>HTML5</strong>和<strong>Javascript</strong>构建的JBrowse通过<strong>AJAX</strong>技术实现了数据的异步加载，所以响应速度非常快。由于Javascript将大量的计算工作在前端完成，服务器端只需要向浏览器客户端发送静态文件，因此也极大程度减轻了服务器端的负担。</p>
<h3 id="准备参考序列"><a href="#准备参考序列" class="headerlink" title="准备参考序列"></a>准备参考序列</h3><p>安装成功之后首先要做的是<strong>格式化参考序列</strong>，支持的格式有fasta， gff，或者是用samtools faidx处理过的indexed fasta 文件。参考序列生成的track 会为后续所有文件提供一个坐标，一直放大后参考序列的碱基也会显示出来。</p>
<p>通常我们使用某一个物种的genome fasta 文件，默认情况下，每一条染色体会独立为一条参考序列。如果想把RNA或者蛋白序列当成参考序列也没有问题。</p>
<p>需要注意的是所有数据默认都会输出在<code>out</code>目录中，如果你想用JBrowse展示不同物种的信息，最好使用<code>--out</code>参数指定单独的目录。</p>
<p>在这里提前说明，后面所有基于命令行设置的配置信息都会自动生成在tarckList.json文件中。</p>
<p>准备参考序列需要用到的是bin目录下的<code>prepare-refseqs.pl</code>脚本</p>
<p><strong>对于VCF文件</strong>，需要提前做的准备就是使用bgzip压缩之后再利用tabix -p vcf 建立index。</p>
<p>展示方式和BigWig类似，其中type要定义为 “JBrowse/View/Track/HTMLVariants”；而storeClass定义为”JBrowse/Store/SeqFeature/VCFTabix” 即可。</p>
</blockquote>
<h2 id="尝试安装"><a href="#尝试安装" class="headerlink" title="尝试安装"></a>尝试安装</h2><p>主要参考这篇文献</p>
<p><a href="https://yq.aliyun.com/articles/650480" target="_blank" rel="noopener">https://yq.aliyun.com/articles/650480</a></p>
<p><strong>没有成功，应该是perl模块的安装问题。不知道是否和conda有关。</strong></p>
<blockquote>
<p>! Installing GD failed. See /root/.cpanm/work/1551106022.8560/build.log for details. Retry with –force to force install it.<br>Searching XML::LibXML (0) on cpanmetadb …<br>Already tried XML-LibXML-2.0134. Skipping.<br>! Installing the dependencies failed: Module ‘XML::LibXML’ is not installed, Module ‘XML::LibXML::Reader’ is not installed, Module ‘GD’ is not install<br>ed, Module ‘DBI’ is not installed, Module ‘DB_File’ is not installed<br>! Bailing out the installation for BioPerl-1.7.5.<br>Searching JSON::XS (0) on cpanmetadb …<br>Unpacking JSON-XS-4.01.tar.gz<br>FAIL</p>
</blockquote>
<blockquote>
<p>! Installing JSON::XS failed. See /root/.cpanm/work/1551106022.8560/build.log for details. Retry with –force to force install it.<br>Searching Bio::Root::Version (1.006000) on cpanmetadb …</p>
</blockquote>
<blockquote>
<p>-&gt; FAIL Installing the dependencies failed: Module ‘DBI’ is not installed, Module ‘Heap::Simple::XS’ is not installed, Module ‘Bio::Annotation::Simple<br>Value’ is not installed, Module ‘Bio::SeqFeature::Annotated’ is not installed, Module ‘DB_File’ is not installed, Module ‘Bio::Index::Fasta’ is not in<br>stalled, Module ‘Bio::SeqFeature::Lite’ is not installed, Module ‘DBD::SQLite’ is not installed, Module ‘Devel::Size’ is not installed, Module ‘Bio::F<br>eatureIO’ is not installed, Module ‘JSON::XS’ is not installed, Module ‘Bio::Root::Version’ is not installed, Module ‘PerlIO::gzip’ is not installed,<br>Module ‘Bio::OntologyIO’ is not installed<br>-&gt; FAIL Bailing out the installation for JBrowse-.</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">perl -MCPAN -e shell</span><br><span class="line">install DBI</span><br><span class="line"></span><br><span class="line">conda install -c bioconda perl-module-list</span><br><span class="line">conda install -c bioconda perl-dbi</span><br><span class="line">conda install -c bioconda perl-bioperl </span><br><span class="line"></span><br><span class="line">instmodsh</span><br><span class="line">locate XML/SAX.pm</span><br></pre></td></tr></table></figure>
<p><img src="images/1551113280461.png" alt="1551113280461"></p>
<blockquote>
<p>/home/conda/feedstock_root/build_artifacts/perl_1548813468557/_build_env/bin/x86_64-conda_cos6-linux-gnu-gcc: No such file or directory<br>make: *** [Perl.o] Error 127</p>
</blockquote>
<h2 id="docker安装（没有成功）"><a href="#docker安装（没有成功）" class="headerlink" title="docker安装（没有成功）"></a>docker安装（没有成功）</h2><p><a href="http://www.runoob.com/docker/centos-docker-install.html" target="_blank" rel="noopener">http://www.runoob.com/docker/centos-docker-install.html</a></p>
<p>安装docker很顺畅</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line">sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line">sudo yum makecache fast</span><br><span class="line">sudo yum -y install docker-ce</span><br><span class="line">sudo systemctl start docker</span><br><span class="line">docker run hello-world</span><br></pre></td></tr></table></figure>
<p><strong>由于本地没有hello-world这个镜像，所以会下载一个hello-world的镜像，并在容器内运行。</strong></p>
<p><a href="https://hub.docker.com/r/jbrowse/gmod-jbrowse/" target="_blank" rel="noopener">jbrowse/gmod-jbrowse</a> 卡住了</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 8080:80 jbrowse/jbrowse-1.12.0</span><br><span class="line"><span class="meta">#</span> 有问题</span><br></pre></td></tr></table></figure>
<h2 id="conda-安装（安装成功了，不知道如何启用）"><a href="#conda-安装（安装成功了，不知道如何启用）" class="headerlink" title="conda 安装（安装成功了，不知道如何启用）"></a>conda 安装（安装成功了，不知道如何启用）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 需要超级用户权限，不然会失败</span><br><span class="line">conda install -c bioconda jbrowse</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> conda 的卸载命令</span><br><span class="line">conda list | grep jbrowse</span><br><span class="line">conda remove jbrowse</span><br></pre></td></tr></table></figure>
<h2 id="安装Nginx"><a href="#安装Nginx" class="headerlink" title="安装Nginx"></a>安装Nginx</h2><p><code>yum install nginx</code></p>
<blockquote>
<p>[root@localhost qi]#  netstat -ntpl<br>Active Internet connections (only servers)<br>Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name<br>tcp        0      0 0.0.0.0:111             0.0.0.0:<em>               LISTEN      1/systemd<br>tcp        0      0 0.0.0.0:80              0.0.0.0:</em>               LISTEN      1823/nginx: master<br>tcp        0      0 0.0.0.0:6000            0.0.0.0:<em>               LISTEN      6706/X<br>tcp        0      0 192.168.122.1:53        0.0.0.0:</em>               LISTEN      6629/dnsmasq<br>tcp        0      0 0.0.0.0:22              0.0.0.0:<em>               LISTEN      6296/sshd<br>tcp        0      0 127.0.0.1:631           0.0.0.0:</em>               LISTEN      6299/cupsd<br>tcp        0      0 127.0.0.1:6010          0.0.0.0:<em>               LISTEN      13051/sshd: qi@pts/<br>tcp        0      0 127.0.0.1:6011          0.0.0.0:</em>               LISTEN      23741/sshd: qi@pts/<br>tcp        0      0 127.0.0.1:6012          0.0.0.0:<em>               LISTEN      31798/sshd: qi@pts/<br>tcp6       0      0 :::3306                 :::</em>                    LISTEN      7024/mysqld<br>tcp6       0      0 :::111                  :::<em>                    LISTEN      1/systemd<br>tcp6       0      0 :::80                   :::</em>                    LISTEN      1823/nginx: master<br>tcp6       0      0 :::6000                 :::<em>                    LISTEN      6706/X<br>tcp6       0      0 :::22                   :::</em>                    LISTEN      6296/sshd<br>tcp6       0      0 ::1:631                 :::<em>                    LISTEN      6299/cupsd<br>tcp6       0      0 ::1:6010                :::</em>                    LISTEN      13051/sshd: qi@pts/<br>tcp6       0      0 ::1:6011                :::<em>                    LISTEN      23741/sshd: qi@pts/<br>tcp6       0      0 ::1:6012                :::</em>                    LISTEN      31798/sshd: qi@pts/ </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kill 1823</span><br><span class="line">service nginx star</span><br></pre></td></tr></table></figure>
<p><a href="https://www.jianshu.com/p/7986bcab355c" target="_blank" rel="noopener">Centos7 yum配置Nginx</a></p>
<blockquote>
<p>/home/qi/miniconda3/pkgs/jbrowse-1.16.2-pl526h6bb024c_6/opt/jbrowse</p>
</blockquote>
<p>又卸载<code>yum remove nginx</code></p>
<h2 id="成功的操作"><a href="#成功的操作" class="headerlink" title="成功的操作"></a>成功的操作</h2><ol>
<li>将web服务器换成了apache，放文件的目录就是 /var/www/html</li>
</ol>
<p><a href="https://www.linode.com/docs/web-servers/apache/install-and-configure-apache-on-centos-7/" target="_blank" rel="noopener">How to Install Apache on CentOS 7</a></p>
<p><a href="https://www.jianshu.com/p/a482a0f8adfd" target="_blank" rel="noopener">CentOS 7 安装 Apache, MySQL, PHP 指南</a></p>
<p><img src="/images/Apache.png" alt=""></p>
<ol start="2">
<li><a href="https://jbrowse.org/blog/" target="_blank" rel="noopener">Jbrowse下载安装</a></li>
</ol>
<p>下面这句话很关键，提到了不用 root 或 sudo 安装。我也不知道为什么，这部分：</p>
<p><strong>Installing Perl prerequisites 成功。这是昨天一直没成功的地方</strong></p>
<p>Formatting data 失败。提取报错信息里的命令，运行，获取错误信息。<strong>Can’t locate local/lib.pm</strong></p>
<p><a href="http://gmod.org/wiki/JBrowse_Configuration_Guide#Making_a_New_JBrowse" target="_blank" rel="noopener">3. Run the automated-setup script, <code>./setup.sh</code>, which will attempt to install all of JBrowse’s (modest) prerequisites for you in the <code>jbrowse/</code> directory itself. Note that <code>setup.sh</code> should not be run as root or with <code>sudo</code>.</a></p>
<blockquote>
<p>(py3.6) [qi@localhost JBrowse-1.16.3]$ ./setup.sh<br>Gathering system information …done.<br>NOTE: Legacy scripts wig-to-json.pl and bam-to-json.pl have been removed from setup. Their functionality has been superseded by add-bam-track.pl and add-bw-track.pl. If you require the old versions, please use JBrowse 1.12.3 or earlier.<br>Minimal release, skipping node and Webpack build<br>Installing Perl prerequisites …done.</p>
<p>Formatting Volvox example data … failed.  See setup.log file for error messages.</p>
<p>Formatting Yeast example data … failed.  See setup.log file for error messages.</p>
</blockquote>
<blockquote>
<p>Formatting Volvox example data …</p>
<ul>
<li>rm -rf sample_data/json/volvox</li>
<li>bin/prepare-refseqs.pl –fasta docs/tutorial/data_files/volvox.fa –out sample_data/json/volvox<br>Attempting to create directory /var/www/html/JBrowse-1.16.3/bin/../src/perl5/../../extlib<br>mkdir sample_data/json/volvox: Permission denied at /var/www/html/JBrowse-1.16.3/bin/../src/perl5/JsonFileStorage.pm line 64.</li>
</ul>
<p>Formatting Yeast example data …</p>
<ul>
<li>rm -rf sample_data/json/yeast/</li>
<li>bin/prepare-refseqs.pl –fasta sample_data/raw/yeast_scaffolds/chr1.fa.gz –fasta sample_data/raw/yeast_scaffolds/chr2.fa.gzip –out sample_data/json/yeast/<br>mkdir sample_data/json/yeast/: Permission denied at /var/www/html/JBrowse-1.16.3/bin/../src/perl5/JsonFileStorage.pm line 64.</li>
</ul>
</blockquote>
<blockquote>
<p><strong>Can’t locate local/lib.pm</strong> in @INC (@INC contains: /var/www/html/JBrowse-1.16.3/bin/../src/perl5/../../extlib/lib/perl5/5.16.3/x86_64-linux-thread-multi <strong>/var/www/html/JBrowse-1.16.3/bin/../src/perl5/../../extlib/lib/perl5/5.16.3</strong> /var/www/html/JBrowse-1.16.3/bin/../src/perl5/../../extlib/lib/perl5/x86_64-linux-thread-multi /var/www/html/JBrowse-1.16.3/bin/../src/perl5/../../extlib/lib/perl5 /var/www/html/JBrowse-1.16.3/bin/../src/perl5 /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at /var/www/html/JBrowse-1.16.3/bin/../src/perl5/JBlibs.pm line 25.<br>Compilation failed in require at bin/prepare-refseqs.pl line 5.<br>BEGIN failed–compilation aborted at bin/prepare-refseqs.pl line 5</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">locate local/lib.pm</span><br><span class="line">cp -r /home/qi/perl5/lib/perl5/local /var/www/html/JBrowse-1.16.3/bin/../src/perl5/../../extlib/lib/perl5/5.16.3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sudo bin/prepare-refseqs.pl --fasta docs/tutorial/data_files/volvox.fa --out sample_data/json/volvox</span><br><span class="line"></span><br><span class="line">sudo bin/prepare-refseqs.pl --fasta sample_data/raw/yeast_scaffolds/chr1.fa.gz --fasta sample_data/raw/yeast_scaffolds/chr2.fa.gzip --out sample_data/json/yeast/</span><br></pre></td></tr></table></figure>
<p>地址：</p>
<p><a href="http://10.164.6.154/JBrowse-1.16.3/index.html?data=sample_data/json/volvox" target="_blank" rel="noopener">http://10.164.6.154/JBrowse-1.16.3/index.html?data=sample_data/json/volvox</a></p>
<p><strong>2019-2-28 19:53:01</strong></p>
<p>今天登入ip的时候，没有显示。</p>
<p>Enable Apache to start at boot, and restart the service for the above changes to take effect:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl enable httpd.service</span><br><span class="line">sudo systemctl restart httpd.service</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 确认http服务是否开启，端口 80</span><br><span class="line">sudo systemctl is-enabled httpd.service</span><br><span class="line"><span class="meta">#</span> 查看历史记录，awk去掉第一列，sed去掉行首空格</span><br><span class="line">history | tail -n 40 | awk '&#123;$1="";print $0&#125;' | sed 's/^ *//'</span><br></pre></td></tr></table></figure>
<h2 id="准备参考序列和特征数据"><a href="#准备参考序列和特征数据" class="headerlink" title="准备参考序列和特征数据"></a>准备参考序列和特征数据</h2><p>JBrowser 用的是 perl 5.16.3</p>
<p><strong>所有track都生成在默认的data目录中</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 指定perl为/usr/bin/perl </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> seq  trackList.json  tracks.conf</span><br><span class="line">/usr/bin/perl bin/prepare-refseqs.pl --fasta ~/data2/tan_rna/genome/HWB.chromosome.fa</span><br><span class="line"><span class="meta">#</span> tracks</span><br><span class="line">/usr/bin/perl bin/flatfile-to-json.pl --gff HWB.gene.models.gff3 --trackType CanvasFeatures --trackLabel HWBgff</span><br></pre></td></tr></table></figure>
<p>不指定会出现如下错误：[^1]</p>
<blockquote>
<p>(base) [qi@localhost JBrowse-1.16.3]$ bin/flatfile-to-json.pl –help<br>perl: symbol lookup error: /var/www/html/JBrowse-1.16.3/bin/../src/perl5/../../extlib/lib/perl5/x86_64-linux-thread-multi/auto/JSON/XS/XS.so: undefined symbol: Perl_xs_apiversion_bootcheck</p>
</blockquote>
<p>查资料</p>
<p><strong>This type of error is almost always indicates you are loading a module that was installed using  a different build of Perl.</strong></p>
<p><a href="https://stackoverflow.com/questions/51375821/perl-xs-apiversion-bootcheck" target="_blank" rel="noopener">https://stackoverflow.com/questions/51375821/perl-xs-apiversion-bootcheck</a></p>
<p>[^1]: 不指定，如果用sudo 也不会出现错误，如：<code>sudo bin/prepare-refseqs.pl --fasta ~/data2/tan_rna/genome/HWB.chromosome.fa --out sample_data/json/HWB</code> 不清楚原因</p>
<h2 id="建立索引方便搜索"><a href="#建立索引方便搜索" class="headerlink" title="建立索引方便搜索"></a>建立索引方便搜索</h2><p>缺这一步，搜索功能不能用</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 生成 ./data/names</span><br><span class="line">/usr/bin/perl bin/generate-names.pl</span><br></pre></td></tr></table></figure>
<p><a href="http://10.164.6.154/JBrowse-1.16.3/index.html?data=data" target="_blank" rel="noopener">http://10.164.6.154/JBrowse-1.16.3/index.html?data=data</a></p>
<h2 id="VCF-tracks"><a href="#VCF-tracks" class="headerlink" title="VCF tracks"></a>VCF tracks</h2><p><a href="http://jbrowse.org/docs/variants.html" target="_blank" rel="noopener">http://jbrowse.org/docs/variants.html</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for i in *.vcf; do bgzip $i; done</span><br><span class="line"></span><br><span class="line">for i in *.vcf.gz; do tabix -p vcf $i; done</span><br></pre></td></tr></table></figure>
<p><img src="https://github.com/qizhengyang2017/qizhengyang2017.github.io/blob/master/images/vcferror.png?raw=true" alt=""></p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://qizhengyang2017.github.io/2019/02/20/snakemake/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qizhengyang">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/20/snakemake/" itemprop="url">
                  使用GATK和snakemake框架的总结
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-20 12:00:57" itemprop="dateCreated datePublished" datetime="2019-02-20T12:00:57+08:00">2019-02-20</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-02-27 17:31:34" itemprop="dateModified" datetime="2019-02-27T17:31:34+08:00">2019-02-27</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<h2 id="标准流程"><a href="#标准流程" class="headerlink" title="标准流程"></a>标准流程</h2><p><img src="https://us.v-cdn.net/5019796/uploads/FileUpload/fa/e60ecf89bd1b2645d9fce68ccf3919.png" alt=""></p>
<h2 id="检查md5值"><a href="#检查md5值" class="headerlink" title="检查md5值"></a>检查md5值</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">md5sum -c checksums.md5</span><br><span class="line"><span class="meta">#</span> 报错,使用dos2unix转化格式</span><br></pre></td></tr></table></figure>
<h2 id="trimmomatic"><a href="#trimmomatic" class="headerlink" title="trimmomatic"></a>trimmomatic</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 2019-2-12 17:16:35 trim</span><br><span class="line">for i in *_1.clean.fq.gz</span><br><span class="line">do</span><br><span class="line">  trimmomatic PE -threads 8 -phred33 $i $&#123;i/_1/_2&#125; -baseout $&#123;i:0:7&#125;.fq.gz \</span><br><span class="line">  ILLUMINACLIP:/home/qi/miniconda3/share/trimmomatic-0.38-1/adapters/TruSeq3-PE.fa:2:30:10 \</span><br><span class="line">  LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p><strong>2019-2-13 12:55:38</strong>  查看结果，只trim了一部分，查看trim.log。HB-9-3终止。</p>
<p><img src="/images/GATK/trimlog.PNG" alt=""></p>
<p><code>ps -aux | grep trimmomatic</code> 查看任务是否还在运行。没有在运行。程序不知什么原因意外中断，来的时候xshell也没有连上服务器，怀疑是服务器自动重启了。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">nohup mv HB-*.fq.gz trim &amp;</span><br><span class="line">rm nohup.out</span><br><span class="line">cd trim</span><br><span class="line">rm HB-9-3__*fq.gz</span><br><span class="line">mv HB-9-3* ..</span><br><span class="line">cd ..</span><br><span class="line"><span class="meta">#</span> trim剩下的fq.gz</span><br><span class="line">nohup time bash trim.sh &gt; trim.log 2&gt;&amp;1 &amp;</span><br><span class="line">jobs</span><br><span class="line">ps -aux | grep trimmomatic</span><br></pre></td></tr></table></figure>
<p><strong>2019-2-13 17:06:38</strong>  查看任务，意外终止。NH-11-2</p>
<p><img src="/images/GATK/NH-11.PNG" alt=""></p>
<p>移动、删除文件，reboot，重新执行脚本。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup time bash trim.sh &gt;&gt; trim.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
<p><strong>2019-2-13 19:35:51</strong>  查看，又意外停止</p>
<p>查看系统最后重启时间</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">who -b</span><br></pre></td></tr></table></figure>
<p><img src="/images/GATK/boot.PNG" alt=""></p>
<p><strong>显然，服务器会自动重启。</strong></p>
<p><img src="/images/GATK/reboot_time.PNG" alt=""></p>
<p>不运行任务的时候，不会重启。是因为CPU温度过高？</p>
<p>更改脚本试一试，把-threads 8 改成 4</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for i in *_1.clean.fq.gz</span><br><span class="line">do</span><br><span class="line">  trimmomatic PE -threads 4 -phred33 $i $&#123;i/_1/_2&#125; -baseout $&#123;i:0:7&#125;.fq.gz \</span><br><span class="line">  ILLUMINACLIP:/home/qi/miniconda3/share/trimmomatic-0.38-1/adapters/TruSeq3-PE.fa:2:30:10 \</span><br><span class="line">  LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup time bash trim.sh &gt; trim.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
<p>没有效果</p>
<p>threads改成16</p>
<p>一小时不到又重启了。。</p>
<p><img src="/images/1550064063962.png" alt="1550064063962"></p>
<p><strong>2019-2-14 16:16:57</strong> </p>
<p><img src="/images/1550132224212.png" alt="1550132224212"></p>
<h2 id="质检"><a href="#质检" class="headerlink" title="质检"></a>质检</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fastqc *.fq.gz -o qcDIR/ -t 6 -d qcDIR/ &gt;&gt;fastqc.r.log 2&gt;&gt;fastqc.e.log</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c bioconda multiqc</span><br></pre></td></tr></table></figure>
<p>做multiqc之前构建一个python3的虚拟环境</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">python --version</span><br><span class="line">conda create --name py3.6 python=3.6</span><br><span class="line">source activate py3.6</span><br><span class="line"><span class="meta">#</span> You'll want to add the source activate py3.6 line to your .bashrc file so that the environment is loaded every time you load the terminal.</span><br><span class="line"><span class="meta">#</span> conda deactivate</span><br><span class="line"><span class="meta">#</span> conda activate py3.6</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> Windows: activate py3.6</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 需要重新安装</span><br><span class="line">conda install -c bioconda multiqc</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>利用multiqc整合结果，方便批量查看</span><br><span class="line">mkdir qcDIR_multiqc</span><br><span class="line">multiqc qcDIR/ -o qcDIR_multiqc/</span><br></pre></td></tr></table></figure>
<h2 id="用-snakemake-编写任务流程"><a href="#用-snakemake-编写任务流程" class="headerlink" title="用 snakemake 编写任务流程"></a>用 snakemake 编写任务流程</h2><p>snakemake是一个用来编写任务流程的工具，用python写的，因此其执行的流程脚本也比较通俗易懂，易于理解，可以看做用户友好版的make。（make在安装软件的时候会用到，没有研究过makefile文件，对它的用处不是太了解。）</p>
<p>其实流程控制是复杂任务（在生信领域很常见）必需的关注点。只是snakemake对于代码功力不够的人来说，在写好代码与重复流程的花销的trade off上，还不如一遍遍重复流程。。但是真的是一个写好了就很好用的东西。</p>
<p>snakemake能够使用<strong>文件名通配</strong>的方式对一类文件进行处理</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> installing</span><br><span class="line">conda install -c bioconda snakemake</span><br></pre></td></tr></table></figure>
<h3 id="简单的例子"><a href="#简单的例子" class="headerlink" title="简单的例子"></a>简单的例子</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cd $HOME</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> Create a folder where we will run our commands:</span><br><span class="line">mkdir snakemake-example</span><br><span class="line">cd snakemake-example</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> Make a fake genome:</span><br><span class="line">touch genome.fa</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> Make some fake data:</span><br><span class="line">mkdir fastq</span><br><span class="line">touch fastq/Sample1.R1.fastq.gz fastq/Sample1.R2.fastq.gz</span><br><span class="line">touch fastq/Sample2.R1.fastq.gz fastq/Sample2.R2.fastq.gz</span><br></pre></td></tr></table></figure>
<p>snakemake 脚本</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">SAMPLES = ['Sample1', 'Sample2']</span><br><span class="line"></span><br><span class="line">rule all:</span><br><span class="line">    input:</span><br><span class="line">        expand('&#123;sample&#125;.txt', sample=SAMPLES)</span><br><span class="line"></span><br><span class="line">rule quantify_genes:</span><br><span class="line">    input:</span><br><span class="line">        genome = 'genome.fa',</span><br><span class="line">        r1 = 'fastq/&#123;sample&#125;.R1.fastq.gz',</span><br><span class="line">        r2 = 'fastq/&#123;sample&#125;.R2.fastq.gz'</span><br><span class="line">    output:</span><br><span class="line">        '&#123;sample&#125;.txt'</span><br><span class="line">    shell:</span><br><span class="line">        'echo &#123;input.genome&#125; &#123;input.r1&#125; &#123;input.r2&#125; &gt; &#123;output&#125;'</span><br></pre></td></tr></table></figure>
<p>学院集群上运行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">snakemake --snakefile Snakefile</span><br></pre></td></tr></table></figure>
<p><img src="/images/1550217959613.png" alt="1550217959613"></p>
<p><img src="/images/1550218038489.png" alt="1550218038489"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 可视化</span><br><span class="line">snakemake --forceall --dag | dot -Tpng &gt; dag1.png</span><br></pre></td></tr></table></figure>
<p><img src="/images/dag1.png" alt="dag1"></p>
<h3 id="snakemake-规则"><a href="#snakemake-规则" class="headerlink" title="snakemake 规则"></a>snakemake 规则</h3><ul>
<li>Snakemake基于规则执行命令，规则一般由input, output,shell三部分组成。除了rule all，其余必须有output</li>
<li>Snakemake可以自动确定不同规则的输入输出的依赖关系，根据<strong>时间戳</strong>来判断文件是否需要重新生成</li>
<li>Snakemake以{sample}.fa形式进行<strong>文件名通配</strong>，用{wildcards.sample}获取sample的实际文件名</li>
<li>Snakemake用expand()生成多个文件名，本质是Python的列表推导式</li>
<li>Snakemake可以在规则外直接写Python代码，在规则内的run里也可以写Python代码。</li>
<li>Snakefile的第一个规则通常是rule all，根据all里的文件决定执行哪些rule。如上面的例子，注释掉all里的input则不执行第二条rule，<strong>（推断未尝试：rule all里定义最终的输出文件，程序也能执行，那么rule里的输出文件在什么时候会被删除，是在所有rule运行完之后，还是在判断出该输出文件不会被用到的时候？）</strong></li>
<li>在output中的结果文件可以是未存在目录中的文件,这时会自动创建不存在的目录（不需要事先建文件夹，这个功能实在是方便）</li>
</ul>
<h3 id="snakemake-命令"><a href="#snakemake-命令" class="headerlink" title="snakemake 命令"></a>snakemake 命令</h3><ol>
<li><p>wildcards: 用来获取通配符匹配到的部分，例如对于通配符”{dataset}/file.{group}.txt”匹配到文件101/file.A.txt，则{wildcards.dataset}就是101，{wildcards.group}就是A。</p>
</li>
<li><p>temp: 通过temp方法可以在所有rule运行完后删除指定的中间文件，eg.output: temp(“f1.bam”)。</p>
</li>
<li><p>protected: 用来指定某些<strong>中间文件是需要保留的</strong>，eg.output: protected(“f1.bam”)。</p>
</li>
</ol>
<h3 id="snakemake-执行"><a href="#snakemake-执行" class="headerlink" title="snakemake 执行"></a>snakemake 执行</h3><p>一般讲所有的参数配置写入Snakefile后直接在Snakefile所在路径执行snakemake命令即可开始执行流程任务，如果只有一个snakefile的话，连文件都不用写。一些常用的参数：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">--snakefile, -s 指定Snakefile，否则是当前目录下的Snakefile</span><br><span class="line">--dryrun, -n  不真正执行，一般用来查看Snakefile是否有错</span><br><span class="line">--printshellcmds, -p   输出要执行的shell命令</span><br><span class="line">--reason, -r  输出每条rule执行的原因,默认FALSE</span><br><span class="line">--cores, --jobs, -j  指定运行的核数，若不指定，则使用最大的核数</span><br><span class="line">--force, -f 重新运行第一条rule或指定的rule</span><br><span class="line">--forceall, -F 重新运行所有的rule，不管是否已经有输出结果</span><br><span class="line">--forcerun, -R 重新执行Snakefile，当更新了rule时候使用此命令</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>一些可视化命令</span><br><span class="line"><span class="meta">$</span> snakemake --dag | dot -Tpdf &gt; dag.pdf</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>集群投递</span><br><span class="line">snakemake --cluster "qsub -V -cwd -q 节点队列" -j 10</span><br><span class="line"><span class="meta">#</span> --cluster: 集群运行指令</span><br><span class="line"><span class="meta">#</span> qusb -V -cwd -q， 表示输出当前环境变量(-V),在当前目录下运行(-cwd), 投递到指定的队列(-q), 如果不指定则使用任何可用队列</span><br><span class="line"><span class="meta">#</span> --local-cores N: 在每个集群中最多并行N核</span><br><span class="line"><span class="meta">#</span> --cluster-config/-u FILE: 集群配置文件</span><br></pre></td></tr></table></figure>
<h3 id="snakemake-实践"><a href="#snakemake-实践" class="headerlink" title="snakemake 实践"></a>snakemake 实践</h3><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2019-2-19 10:28:52 part</span></span><br><span class="line"><span class="comment"># GATK snakemake</span></span><br><span class="line"><span class="comment"># qizhengyang</span></span><br><span class="line"></span><br><span class="line">from os.path import join</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">GENOME = 'genome/HWB.chromosome.fa'</span><br><span class="line">GTF = 'genes/HWB.gene.models.gtf'</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(SAMPLES,) = glob_wildcards('pairedDIR/&#123;sample&#125;_1P.fq.gz')</span><br><span class="line">PATTERN_R1 = join('pairedDIR', '&#123;sample&#125;_1P.fq.gz')</span><br><span class="line">PATTERN_R2 = join('pairedDIR', '&#123;sample&#125;_2P.fq.gz')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">rule all:</span><br><span class="line">    input:</span><br><span class="line">        'star_index_2pass/',</span><br><span class="line">        expand('star_1pass/&#123;sample&#125;SJ.out.tab', sample=SAMPLES),</span><br><span class="line">        'star_index_2pass/',</span><br><span class="line">        expand('star_2pass/&#123;sample&#125;Aligned.out.sam', sample=SAMPLES),</span><br><span class="line">        expand('star_2pass/&#123;sample&#125;_rg_added_sorted.bam', sample=SAMPLES),</span><br><span class="line">        expand('star_2pass/&#123;sample&#125;_dedup.bam', sample=SAMPLES),</span><br><span class="line">        expand('star_2pass/&#123;sample&#125;_dedup_split.bam', sample=SAMPLES),</span><br><span class="line">        expand('star_2pass/&#123;sample&#125;.vcf', sample=SAMPLES),</span><br><span class="line">        expand('star_2pass/&#123;sample&#125;_filtered.vcf', sample=SAMPLES)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">rule star_index:</span><br><span class="line">    input:</span><br><span class="line">        genome = GENOME,</span><br><span class="line">        gtf = GTF</span><br><span class="line">    output:</span><br><span class="line">        <span class="comment"># 最后加上 directory()，不然在集群上运行会报错</span></span><br><span class="line">        star_index = directory('star_index/')</span><br><span class="line"></span><br><span class="line">    log:</span><br><span class="line">        'star_index.log'</span><br><span class="line">    threads: 8</span><br><span class="line">    run:</span><br><span class="line">        <span class="comment"># star 1-pass index, OK</span></span><br><span class="line">        shell('STAR --runThreadN &#123;threads&#125; --runMode genomeGenerate'</span><br><span class="line">              ' --genomeDir &#123;output.star_index&#125;'</span><br><span class="line">              ' --genomeFastaFiles &#123;input.genome&#125;'</span><br><span class="line">              ' --sjdbGTFfile &#123;input.gtf&#125;'</span><br><span class="line">              ' 2&gt; &#123;log&#125;')</span><br><span class="line"></span><br><span class="line">rule star_1pass_align:</span><br><span class="line">    input:</span><br><span class="line">        index = 'star_index/',</span><br><span class="line">        r1 = PATTERN_R1,</span><br><span class="line">        r2 = PATTERN_R2</span><br><span class="line">    output:</span><br><span class="line">        index = 'star_1pass/&#123;sample&#125;SJ.out.tab'</span><br><span class="line">    threads: 8</span><br><span class="line">    params:</span><br><span class="line">        prefix = './star_1pass/&#123;sample&#125;'</span><br><span class="line">    <span class="comment"># 在使用params之前是报错的，NameError,The name 'sample' is unknown in this context</span></span><br><span class="line">    run:</span><br><span class="line">        <span class="comment"># star 1-pass align, OK</span></span><br><span class="line">        shell('STAR --runThreadN &#123;threads&#125; --genomeDir &#123;input.index&#125;'</span><br><span class="line">              ' --readFilesIn &#123;input.r1&#125; &#123;input.r2&#125;'</span><br><span class="line">              ' --readFilesCommand zcat'</span><br><span class="line">              ' --outFileNamePrefix &#123;params.prefix&#125;')</span><br><span class="line"></span><br><span class="line">rule star_2pass_index:</span><br><span class="line">    input:</span><br><span class="line">        genome = GENOME,</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 这里必需加expand，不然会报错：Wildcards in input files cannot be determined from output files:</span></span><br><span class="line">        <span class="comment"># 'sample'。</span></span><br><span class="line">        <span class="comment"># 报错信息说通配的信息不能从output里推断出来，因为我的output是文件夹。input应该是所有样品的信息，可以用expand函数，这样通配的问题就没有了。</span></span><br><span class="line">        <span class="comment"># 然后用--sjdbFileChrStartEnd参数将所有样品的SJ.out.tab文件作为输入的annotated junction进行第二次建index</span></span><br><span class="line">        <span class="comment"># http://www.bioinfo-scrounger.com/archives/288</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 不能加三个引号（"""或'''注释）进行段落注释</span></span><br><span class="line"></span><br><span class="line">        splice_site = expand('star_1pass/&#123;sample&#125;SJ.out.tab', sample=SAMPLES)</span><br><span class="line">    output:</span><br><span class="line">        index = directory('star_index_2pass/')</span><br><span class="line">    threads: 8</span><br><span class="line">    run:</span><br><span class="line">        <span class="comment"># star 2-pass index, OK</span></span><br><span class="line">        shell('STAR --runThreadN &#123;threads&#125; --runMode genomeGenerate'</span><br><span class="line">              ' --genomeDir &#123;output.index&#125;'</span><br><span class="line">              ' --genomeFastaFiles &#123;input.genome&#125;'</span><br><span class="line">              ' --sjdbFileChrStartEnd &#123;input.splice_site&#125;')</span><br><span class="line"></span><br><span class="line">rule star_2pass_align:</span><br><span class="line">    input:</span><br><span class="line">        index = 'star_index_2pass/',</span><br><span class="line">        r1 = PATTERN_R1,</span><br><span class="line">        r2 = PATTERN_R2</span><br><span class="line">    output:</span><br><span class="line">        sam = 'star_2pass/&#123;sample&#125;Aligned.out.sam'</span><br><span class="line">    threads: 8</span><br><span class="line">    params:</span><br><span class="line">        prefix = 'star_2pass/&#123;sample&#125;'</span><br><span class="line">    run:</span><br><span class="line">        <span class="comment"># star 2-pass align</span></span><br><span class="line">        shell('STAR --runThreadN &#123;threads&#125; --genomeDir &#123;input.index&#125;'</span><br><span class="line">              ' --readFilesIn &#123;input.r1&#125; &#123;input.r2&#125;'</span><br><span class="line">              ' --readFilesCommand zcat'</span><br><span class="line">              ' --outFileNamePrefix &#123;params.prefix&#125;')</span><br><span class="line"></span><br><span class="line">rule picard:</span><br><span class="line">    input:</span><br><span class="line">        sam = 'star_2pass/&#123;sample&#125;Aligned.out.sam'</span><br><span class="line">    output:</span><br><span class="line">        bam = 'star_2pass/&#123;sample&#125;_rg_added_sorted.bam'</span><br><span class="line">    run:</span><br><span class="line">        <span class="comment"># RGID和RGSM的sample必须是&#123;wildcards.sample&#125;，不然</span></span><br><span class="line">        <span class="comment"># The name 'sample' is unknown in this context. Please make sure that you defined that variable.</span></span><br><span class="line">        <span class="comment"># Also note that braces not used for variable access have to be escaped by repeating them, i.e. &#123;&#123;print $1&#125;&#125;</span></span><br><span class="line">        shell('picard AddOrReplaceReadGroups'</span><br><span class="line">              ' I=&#123;input.sam&#125;'</span><br><span class="line">              ' O=&#123;output.bam&#125;'</span><br><span class="line">              ' SO=coordinate'</span><br><span class="line">              ' RGID=&#123;wildcards.sample&#125;'</span><br><span class="line">              ' RGLB=rna'</span><br><span class="line">              ' RGPL=illumina'</span><br><span class="line">              ' RGPU=hiseq'</span><br><span class="line">              ' RGSM=&#123;wildcards.sample&#125;')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">rule picard_markduplicates:</span><br><span class="line">    input:</span><br><span class="line">        bam = 'star_2pass/&#123;sample&#125;_rg_added_sorted.bam'</span><br><span class="line">    output:</span><br><span class="line">        dedup_bam = 'star_2pass/&#123;sample&#125;_dedup.bam'</span><br><span class="line">    params:</span><br><span class="line">        dedup_metrices = 'star_2pass/&#123;sample&#125;_dedup.metrics'</span><br><span class="line">    run:</span><br><span class="line">        shell('picard MarkDuplicates'</span><br><span class="line">              ' I=&#123;input.bam&#125;'</span><br><span class="line">              ' O=&#123;output.dedup_bam&#125;'</span><br><span class="line">              ' CREATE_INDEX=true'</span><br><span class="line">              ' VALIDATION_STRINGENCY=SILENT'</span><br><span class="line">              ' M=&#123;params.dedup_metrices&#125;')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">rule gatk_split:</span><br><span class="line">    input:</span><br><span class="line">        dedup_bam = 'star_2pass/&#123;sample&#125;_dedup.bam',</span><br><span class="line">        genome = GENOME</span><br><span class="line">    output:</span><br><span class="line">        split_bam = 'star_2pass/&#123;sample&#125;_dedup_split.bam'</span><br><span class="line">    run:</span><br><span class="line">        shell('java -jar $GATK -T SplitNCigarReads'</span><br><span class="line">              ' -R &#123;input.genome&#125;'</span><br><span class="line">              ' -I &#123;input.dedup_bam&#125;'</span><br><span class="line">              ' -o &#123;output.split_bam&#125;'</span><br><span class="line">              ' -rf ReassignOneMappingQuality'</span><br><span class="line">              ' -RMQF 255'</span><br><span class="line">              ' -RMQT 60'</span><br><span class="line">              ' -U ALLOW_N_CIGAR_READS')</span><br><span class="line">rule gatk:</span><br><span class="line">    input:</span><br><span class="line">        bam = 'star_2pass/&#123;sample&#125;_dedup_split.bam',</span><br><span class="line">        genome = GENOME</span><br><span class="line">    output:</span><br><span class="line">        vcf = 'star_2pass/&#123;sample&#125;.vcf'</span><br><span class="line">    run:</span><br><span class="line">        shell('java -jar $GATK -T HaplotypeCaller'</span><br><span class="line">              ' -R &#123;input.genome&#125;'</span><br><span class="line">              ' -I &#123;input.bam&#125;'</span><br><span class="line">              ' -dontUseSoftClippedBases'</span><br><span class="line">              ' -stand_call_conf 20.0'</span><br><span class="line">              ' -o &#123;output.vcf&#125;')</span><br><span class="line"></span><br><span class="line">rule gatk_filter:</span><br><span class="line">    input:</span><br><span class="line">        genome = GENOME,</span><br><span class="line">        vcf = 'star_2pass/&#123;sample&#125;.vcf'</span><br><span class="line">    output:</span><br><span class="line">        'star_2pass/&#123;sample&#125;_filtered.vcf'</span><br><span class="line">    run:</span><br><span class="line">        shell('java -jar $GATK'</span><br><span class="line">              ' -T VariantFiltration'</span><br><span class="line">              ' -R &#123;input.genome&#125;'</span><br><span class="line">              ' -V &#123;input.vcf&#125;'</span><br><span class="line">              ' -window 35'</span><br><span class="line">              ' -cluster 3'</span><br><span class="line">              ' -filterName FS -filter <span class="string">"FS &gt; 30.0"</span>'</span><br><span class="line">              ' -filterName QD -filter <span class="string">"QD &lt; 2.0"</span>'</span><br><span class="line">              ' -o &#123;output&#125;')</span><br></pre></td></tr></table></figure>
<h3 id="实验室服务器试运行"><a href="#实验室服务器试运行" class="headerlink" title="实验室服务器试运行"></a>实验室服务器试运行</h3><ol>
<li>By default snakemake executes the first rule in the snakefile. </li>
<li>output中会自动创建没有的文件夹</li>
</ol>
<p><img src="/images/rull_all.PNG" alt=""></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> cores设置核心数</span><br><span class="line">snakemake -s part.py --cores 8</span><br></pre></td></tr></table></figure>
<p>跑samples中的所有样品</p>
<p><img src="/images/all_test.PNG" alt=""></p>
<p><img src="/images/real.PNG" alt=""></p>
<p>存储空间不够，停止</p>
<p><img src="/images/1550629229697.png" alt="1550629229697"></p>
<p>重新运行之后，是从NH-12-1开始</p>
<p><img src="/images/1550630968765.png" alt="1550630968765"></p>
<p>之前的结果只有NH-12-1Log.out，时间是2019/2/20 3:35 现在是：</p>
<p><img src="/images/1550631201623.png" alt="1550631201623"></p>
<p>说明这个样本从头开始跑了。</p>
<h3 id="集群上运行"><a href="#集群上运行" class="headerlink" title="集群上运行"></a>集群上运行</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 查看节点状态</span><br><span class="line">pestat</span><br><span class="line"><span class="meta">#</span> 测试 dry run</span><br><span class="line">snakemake -n</span><br><span class="line"><span class="meta">#</span> 检测某条rule</span><br><span class="line">snakemake -n -r star_index</span><br><span class="line"><span class="meta">#</span> 可视化</span><br><span class="line"><span class="meta">#</span> snakemake --dag | dot -Tpdf &gt; dag.pdf</span><br><span class="line">snakemake --forceall --dag | dot -Tpdf &gt; dag.pdf</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> # 投递任务 -cwd不能用 [qsub: illegal -c value]</span><br><span class="line"><span class="meta">#</span> snakemake --cluster "qsub -V -cwd -q high" -j 20</span><br><span class="line"></span><br><span class="line">snakemake --cluster "qsub -V -q high" -j 20</span><br><span class="line"><span class="meta">#</span> 报错</span><br><span class="line"><span class="meta">#</span> Complete log: /home02/qizhengyang/qizhengyang/gatk_rna/.snakemake/log/2019-02-20T152054.823542.snakemake.log</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 查看错误信息 输出目录要用 directory() ，在实验室服务器上没有遇上这种情况</span><br><span class="line">less snakejob.star_index.254.sh.e980069</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>ImproperOutputException</strong> in line 30 of /home02/qizhengyang/qizhengyang/gatk_rna/Snakefile:<br>Outputs of incorrect type (directories when expecting files or vice versa). Output directories must be flagged with directory(). for rule star_index:<br>star_index/<br>Removing output files of failed job star_index since they might be corrupted:<br>star_index/<br>Skipped removing non-empty directory star_index/<br>Shutting down, this might take some time.</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">snakemake -s Snakefile1 --cluster "qsub -V -q high" -j 20</span><br><span class="line"><span class="meta">#</span> -j 必须指定，否则Error: you need to specify the maximum number of jobs to be queued or executed at the same time with --jobs.</span><br><span class="line"><span class="meta">#</span> Here, -j denotes the number of jobs submitted being submitted to the cluster at the same time</span><br><span class="line"><span class="meta">#</span> -j 代表可以同时提交的任务数</span><br><span class="line"><span class="meta">#</span> 没有重新运行star_index这个任务</span><br></pre></td></tr></table></figure>
<p><strong>2019-2-20 20:22:01 错误：</strong></p>
<p><img src="/images/1550664537835.png" alt="1550664537835"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">less snakejob.star_1pass_align.28.sh.e980101</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Possible cause 1: not enough RAM. Check if you have enough RAM 6975932175 bytes</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 剩下的三个重新跑 </span><br><span class="line">snakemake -n</span><br><span class="line">snakemake -s Snakefile1 --cluster "qsub -V  -q high" -j 20</span><br></pre></td></tr></table></figure>
<p><strong>没有安装picard</strong>。。这种低级错误千万不能再犯了</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda install -c bioconda picard </span><br><span class="line">snakemake -n</span><br></pre></td></tr></table></figure>
<p><img src="/images/1550717077745.png" alt="1550717077745"></p>
<p><strong>终端意外退出，输出到屏幕上的信息没有了</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ls -a</span><br><span class="line">cd .snakemake/log</span><br><span class="line"><span class="meta">#</span> 按修改时间查看文件</span><br><span class="line"><span class="meta">#</span> l长格式显示，t按时间排序（-r升序）</span><br><span class="line">ls -lth</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> snakemake程序停止</span><br><span class="line"><span class="meta">#</span> 已经提交的任务会运行完</span><br><span class="line">snakemake -n --quiet</span><br></pre></td></tr></table></figure>
<p><img src="/images/1550721693878.png" alt="1550721693878"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">snakemake -s Snakefile1 --cluster "qsub -V -q high" -j 20</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Error: Directory cannot be locked. Please make sure that no other Snakemake process is trying to create the same files in the following directory</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 解决办法 https://zhuanlan.zhihu.com/p/47575136</span><br><span class="line">snakemake --unlock</span><br><span class="line">snakemake -s Snakefile1 --cluster "qsub -V -q high" -j 20</span><br></pre></td></tr></table></figure>
<p><strong>报错</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">less snakejob.star_2pass_align.68.sh.e980306</span><br></pre></td></tr></table></figure>
<blockquote>
<p>libgcc_s.so.1 must be installed for pthread_cancel to work</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">less snakejob.star_2pass_align.68.sh.e980306 </span><br><span class="line"><span class="meta">#</span> 会自动删除失败任务的输出文件</span><br><span class="line"><span class="meta">#</span> Removing output files of failed job star_2pass_align since they might be corrupted:</span><br></pre></td></tr></table></figure>
<p><strong>短暂的断网，与服务器连接中断</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">snakemake -n</span><br><span class="line"><span class="meta">#</span> 报错，因为已经提交的任务没有运行完</span><br></pre></td></tr></table></figure>
<p><img src="/images/1550733778508.png" alt="1550733778508"></p>
<h3 id="nohup将程序放入后台"><a href="#nohup将程序放入后台" class="headerlink" title="nohup将程序放入后台"></a>nohup将程序放入后台</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">whatis  nohup</span><br><span class="line">man 1 nohup</span><br></pre></td></tr></table></figure>
<blockquote>
<p>   If  standard input is a terminal, redirect it from /dev/null.  If standard output is a terminal, append output to ‘nohup.out’ if possible, ‘$HOME/nohup.out’ otherwise.  If standard error is a terminal, redirect it to standard  output.   To  save  output  to FILE, use ‘nohup COMMAND &gt; FILE’.</p>
</blockquote>
<p><strong>重定向与后台运行的知识</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">nohup snakemake -n &amp;</span><br><span class="line"><span class="meta">#</span> [qizhengyang@node1 gatk_rna]$ nohup: 忽略输入并把输出追加到"nohup.out"</span><br><span class="line"></span><br><span class="line">nohup snakemake -n &gt; test_nohup.out 2&gt;&amp;1 &amp;</span><br><span class="line"><span class="meta">#</span> 标准输出和标准错误输出都重定向到文件</span><br><span class="line"></span><br><span class="line">snakemake -n &gt; test_nohup.out 2&gt;&amp;1 &amp;</span><br><span class="line"><span class="meta">#</span> 会产生进程号</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> nohup方式后台运行(&amp;) 忽略所有发送给子命令的挂断（SIGHUP）信号 重定向子命令的标准输出(stdout)和标准错误(stderr)</span><br><span class="line">nohup snakemake -s Snakefile1 --cluster "qsub -V -q high" -j 20 &gt; snakemake.out 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
<h3 id="IP-意外变化"><a href="#IP-意外变化" class="headerlink" title="IP 意外变化"></a>IP 意外变化</h3><p>2019-2-21 16:45:01 实验室的服务器连不上，我查看了ssh server是否开启，查了IP，发现是IP变了。</p>
<h3 id="重新开始"><a href="#重新开始" class="headerlink" title="重新开始"></a>重新开始</h3><h4 id="2019-2-21-21-33-58"><a href="#2019-2-21-21-33-58" class="headerlink" title="2019-2-21 21:33:58"></a>2019-2-21 21:33:58</h4><p>查看了实验室服务器生的Index文件夹，比较了大小，之前第一步需要重做。。很悲惨</p>
<p>gatk加了  -Xmx10g -jar   #   Decrease Java heap size (-Xmx/-Xms)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">snakemake -n -s Snakefile2 --quiet</span><br><span class="line"><span class="meta">#</span> 调了最大并行数，因为会有内存不够的错误</span><br><span class="line">nohup snakemake -s Snakefile2 --cluster "qsub -V -q high" -j 10 &amp;&gt; snakemake.out &amp;</span><br></pre></td></tr></table></figure>
<p><img src="/images/1550759212229.png" alt="1550759212229"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">snakemake --unlock</span><br></pre></td></tr></table></figure>
<p>之后再运行命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">nohup snakemake -s Snakefile2 --cluster "qsub -V -q high" -j 10 &amp;&gt; snakemake.out &amp;</span><br><span class="line"><span class="meta">#</span> snakemake.out内容重新写入</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 查看任务</span><br><span class="line">jobs</span><br><span class="line"><span class="meta">#</span> 或</span><br><span class="line">ps aux|grep Snakefile2|grep -v grep</span><br><span class="line"><span class="meta">#</span> https://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/ps.html</span><br></pre></td></tr></table></figure>
<p>2019-2-22 14:56:03 查看任务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps aux|grep Snakefile2|grep -v grep</span><br></pre></td></tr></table></figure>
<p><img src="/images/1550818567395.png" alt="1550818567395"></p>
<p>这个任务在内存中，但 <code>qstat</code>没有任务在运行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">less snakemake.out</span><br><span class="line">cd .snakemake/log/</span><br><span class="line">ls -thl</span><br><span class="line">less 2019-02-21T224633.856137.snakemake.log # 与snakemake.out里的信息一样，没有错误提示，</span><br><span class="line">snakemake -n -s Snakefile2 --quiet</span><br></pre></td></tr></table></figure>
<p>这个进程kill不掉 <code>kill 7550</code></p>
<p>但是，好像起作用了，log文件时间改了，似乎多了一句话（<strong>下次log文件应该copy一份下来，或者将最后的内容粘贴下来</strong>）</p>
<blockquote>
<p>Will exit after finishing currently running jobs.</p>
</blockquote>
<p><strong>重新运行</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">snakemake --unlock</span><br><span class="line"><span class="meta">#</span> 不放入后台，-j 20，实时监测</span><br><span class="line">snakemake -s Snakefile2 --cluster "qsub -V -q high" -j 20</span><br></pre></td></tr></table></figure>
<p><code>kill -9 7550</code> 有效果</p>
<p><strong>两个进程信息比较</strong></p>
<p><img src="/images/1550823961073.png" alt="1550823961073"></p>
<p>院里集群上的时间快18分钟</p>
<p>报错先查看snakemake.log，然后查看job的std err</p>
<p><strong>star 2pass align 出错</strong></p>
<p><em>2019-2-22 20:06:58</em></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 查看错误信息</span><br><span class="line">less snakejob.star_2pass_align.52.sh.e980754</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Building DAG of jobs…<br>Using shell: /bin/bash<br>Provided cores: 20<br>Rules claiming more threads will be scaled down.<br>Job counts:<br>        count   jobs<br>        1       star_2pass_align<br>        1</p>
<p>[Fri Feb 22 16:44:54 2019]<br>rule star_2pass_align:<br>    input: star_index_2pass/, pairedDIR/OV-9-2_1P.fq.gz, pairedDIR/OV-9-2_2P.fq.gz<br>    output: star_2pass/OV-9-2Aligned.out.sam<br>    jobid: 0<br>    wildcards: sample=OV-9-2<br>    threads: 20</p>
<p><strong>libgcc_s.so.1 must be installed for pthread_cancel to work</strong><br>terminate called after throwing an instance of ‘St9bad_alloc’<br>libgcc_s.so.1 must be installed for pthread_cancel to work<br>  what():  std::bad_alloc<br>[Fri Feb 22 16:46:26 2019]<br>Error in rule star_2pass_align:<br>    jobid: 0<br>    output: star_2pass/OV-9-2Aligned.out.sam</p>
<p>RuleException:<br>CalledProcessError in line 101 of /home02/qizhengyang/qizhengyang/gatk_rna/Snakefile2:<br>Command ‘set -euo pipefail;  STAR –runThreadN 20 –genomeDir star_index_2pass/ –readFilesIn pairedDIR/OV-9-2_1P.fq.gz pairedDIR/OV-9-2_2P.fq.gz –readFilesCommand zcat –outFileNamePrefix star_2pass/OV-9-2’ returned non-zero exit status 141.<br>snakejob.star_2pass_align.52.sh.e980754 </p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 查看任务</span><br><span class="line">qstat</span><br><span class="line">pestat</span><br></pre></td></tr></table></figure>
<p><img src="/images/jobs-1550842252344.PNG" alt=""></p>
<p><img src="/images/align-jobs-1550842283551.PNG" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pbsnodes -a | less</span><br><span class="line">snakemake --cluster --rerun-incomplete qsub --jobs 10</span><br><span class="line"></span><br><span class="line"># qstat -a (for summary)</span><br><span class="line"># qstat -n (You will see where the nodes the job lands)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>[qizhengyang@node1 gatk_rna]$ <code>snakemake -n</code><br>Building DAG of jobs…<br>IncompleteFilesException:<br>The files below seem to be incomplete. If you are sure that certain files are not incomplete, mark them as complete with</p>
<pre><code>snakemake --cleanup-metadata &lt;filenames&gt;
</code></pre><p>To re-generate the files rerun your command with the –rerun-incomplete flag.<br><strong>Incomplete files:</strong><br>star_2pass/OV-10-1Aligned.out.sam<br>star_2pass/NH-10-3Aligned.out.sam<br>star_2pass/OV-10-2Aligned.out.sam<br>star_2pass/NH-11-2Aligned.out.sam<br>star_2pass/HB-9-3Aligned.out.sam<br>star_2pass/HB-10-3Aligned.out.sam</p>
</blockquote>
<p>这样是在当前节点运行的</p>
<blockquote>
<p>[qizhengyang@node1 gatk_rna]$ <code>snakemake --rerun-incomplete</code><br>Building DAG of jobs…<br>Using shell: /bin/bash<br>Provided cores: 1<br><strong>Rules claiming more threads will be scaled down.</strong><br>Job counts:<br>    count    jobs<br>    1    all<br>    36    gatk<br>    36    gatk_filter<br>    36    gatk_split<br>    36    picard<br>    36    picard_markduplicates<br>    25    star_2pass_align<br>    206</p>
<p>[Fri Feb 22 23:06:04 2019]<br>rule picard:<br>    input: star_2pass/OV-12-3Aligned.out.sam<br>    output: star_2pass/OV-12-3_rg_added_sorted.bam<br>    jobid: 101<br>    wildcards: sample=OV-12-3</p>
<p>Job counts:<br>    count    jobs<br>    1    picard<br>    1<br>INFO    2019-02-22 23:06:07    AddOrReplaceReadGroups    </p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 只有胖节点有用，将任务提交到胖节点上，比需指定 -q low。默认是 high，会处于排队状态</span><br><span class="line">snakemake --rerun-incomplete --cluster "qsub -q low" --jobs 10</span><br></pre></td></tr></table></figure>
<p><img src="/images/queue.PNG" alt=""></p>
<blockquote>
<p>[qizhengyang@node1 gatk_rna]$ snakemake –rerun-incomplete –cluster “qsub -q low” –jobs 10<br>Building DAG of jobs…<br>Using shell: /bin/bash<br>Provided cluster nodes: 10<br>Job counts:<br>    count    jobs<br>    1    all<br>    36    gatk<br>    36    gatk_filter<br>    36    gatk_split<br>    36    picard<br>    36    picard_markduplicates<br>    25    star_2pass_align<br>    206</p>
<p>[Fri Feb 22 23:24:56 2019]<br>rule picard:<br>    input: star_2pass/HB-12-1Aligned.out.sam<br>    output: star_2pass/HB-12-1_rg_added_sorted.bam<br>    jobid: 106<br>    wildcards: sample=HB-12-1</p>
<p>Submitted job 106 with external jobid ‘980770.node1’.</p>
<p>[Fri Feb 22 23:24:56 2019]<br>rule picard:<br>    input: star_2pass/NH-9-2Aligned.out.sam<br>    output: star_2pass/NH-9-2_rg_added_sorted.bam<br>    jobid: 108<br>    wildcards: sample=NH-9-2</p>
<p>Submitted job 108 with external jobid ‘980771.node1’.</p>
<p>[Fri Feb 22 23:24:56 2019]<br>rule picard:<br>    input: star_2pass/OV-12-3Aligned.out.sam<br>    output: star_2pass/OV-12-3_rg_added_sorted.bam<br>    jobid: 101<br>    wildcards: sample=OV-12-3</p>
<p>Submitted job 101 with external jobid ‘980772.node1’.</p>
<p>[Fri Feb 22 23:24:56 2019]<br>rule picard:<br>    input: star_2pass/HB-10-1Aligned.out.sam<br>    output: star_2pass/HB-10-1_rg_added_sorted.bam<br>    jobid: 85<br>    wildcards: sample=HB-10-1</p>
<p>Submitted job 85 with external jobid ‘980773.node1’.</p>
<p>[Fri Feb 22 23:24:56 2019]<br>rule picard:<br>    input: star_2pass/NH-9-3Aligned.out.sam<br>    output: star_2pass/NH-9-3_rg_added_sorted.bam<br>    jobid: 74<br>    wildcards: sample=NH-9-3</p>
<p>Submitted job 74 with external jobid ‘980774.node1’.</p>
<p>[Fri Feb 22 23:24:56 2019]<br>rule picard:<br>    input: star_2pass/OV-10-3Aligned.out.sam<br>    output: star_2pass/OV-10-3_rg_added_sorted.bam<br>    jobid: 98<br>    wildcards: sample=OV-10-3</p>
<p>Submitted job 98 with external jobid ‘980775.node1’.</p>
<p>[Fri Feb 22 23:24:57 2019]<br>rule picard:<br>    input: star_2pass/HB-11-2Aligned.out.sam<br>    output: star_2pass/HB-11-2_rg_added_sorted.bam<br>    jobid: 77<br>    wildcards: sample=HB-11-2</p>
<p>Submitted job 77 with external jobid ‘980776.node1’.</p>
<p>[Fri Feb 22 23:24:57 2019]<br>rule picard:<br>    input: star_2pass/OV-11-2Aligned.out.sam<br>    output: star_2pass/OV-11-2_rg_added_sorted.bam<br>    jobid: 90<br>    wildcards: sample=OV-11-2</p>
<p>Submitted job 90 with external jobid ‘980777.node1’.</p>
<p>[Fri Feb 22 23:24:57 2019]<br>rule picard:<br>    input: star_2pass/NH-12-1Aligned.out.sam<br>    output: star_2pass/NH-12-1_rg_added_sorted.bam<br>    jobid: 107<br>    wildcards: sample=NH-12-1</p>
<p>Submitted job 107 with external jobid ‘980778.node1’.</p>
<p>[Fri Feb 22 23:24:57 2019]<br>rule picard:<br>    input: star_2pass/OV-12-1Aligned.out.sam<br>    output: star_2pass/OV-12-1_rg_added_sorted.bam<br>    jobid: 102<br>    wildcards: sample=OV-12-1</p>
<p>Submitted job 102 with external jobid ‘980779.node1’.</p>
</blockquote>
<p><strong>运行时间</strong></p>
<p>picard 半小时，CPU时间是4小时。但是picard我并没有设置使用多少线程。</p>
<p><code>qstat</code></p>
<p><img src="/images/time1.PNG" alt=""></p>
<p><code>qstat -a</code></p>
<p><img src="/images/time2.PNG" alt=""></p>
<p><code>qstat -n</code></p>
<p><img src="/images/qstat-n.PNG" alt=""></p>
<h4 id="2019-2-23-11-02-59"><a href="#2019-2-23-11-02-59" class="headerlink" title="2019-2-23 11:02:59"></a>2019-2-23 11:02:59</h4><blockquote>
<p>Shutting down, this might take some time.<br>Exiting because a job execution failed. Look above for error message<br>Complete log: /home02/qizhengyang/qizhengyang/gatk_rna/.snakemake/log/2019-02-22T232454.376651.snakemake.log</p>
</blockquote>
<p>出错的任务</p>
<blockquote>
<p>[Sat Feb 23 01:21:32 2019]<br>Error in rule picard:<br>    jobid: 88<br>    output: star_2pass/OV-9-2_rg_added_sorted.bam<br>    cluster_jobid: 980797.node1</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">less snakejob.picard.88.sh.e980797</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Building DAG of jobs…<br>Using shell: /bin/bash<br><strong>Provided cores: 96</strong><br>Rules claiming more threads will be scaled down.<br>Job counts:<br>        count   jobs<br>        1       picard<br>        1</p>
<p>[Sat Feb 23 00:58:20 2019]<br>rule picard:<br>    input: star_2pass/OV-9-2Aligned.out.sam<br>    output: star_2pass/OV-9-2_rg_added_sorted.bam<br>    jobid: 0<br>    wildcards: sample=OV-9-2</p>
<p>INFO    2019-02-23 00:58:23     AddOrReplaceReadGroups  </p>
<p><strong><strong>**</strong></strong> NOTE: Picard’s command line syntax is changing.</p>
<hr>
<p><strong><strong>**</strong></strong> For more information, please see:<br><strong><strong>**</strong></strong> <a href="https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition)" target="_blank" rel="noopener">https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition)</a></p>
<hr>
<p><strong><strong>**</strong></strong> The command line looks like this in the new syntax:</p>
<hr>
<p><strong><strong>**</strong></strong>    AddOrReplaceReadGroups -I star_2pass/OV-9-2Aligned.out.sam -O star_2pass/OV-9-2_rg_added_sorted.bam -SO coordinate -RGID OV-9-2 -RGLB rna -RGPL illumina -RGPU hiseq -RGSM OV-9-2</p>
<hr>
<p>00:58:23.874 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home02/qizhengyang/anaconda3/share/picard-2.18.26-0/picard.jar!/<br>com/intel/gkl/native/libgkl_compression.so<br>[Sat Feb 23 00:58:23 CST 2019] AddOrReplaceReadGroups INPUT=star_2pass/OV-9-2Aligned.out.sam OUTPUT=star_2pass/OV-9-2_rg_added_sorted.bam SORT_ORDER=c<br>oordinate RGID=OV-9-2 RGLB=rna RGPL=illumina RGPU=hiseq RGSM=OV-9-2    VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX<br>_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false<br>[Sat Feb 23 00:58:23 CST 2019] Executing as qizhengyang@node21 on Linux 2.6.32-431.el6.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_121-b15; Deflater:<br> Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.18.26-SNAPSHOT<br>INFO    2019-02-23 00:58:27     AddOrReplaceReadGroups  Created read-group ID=OV-9-2 PL=illumina LB=rna SM=OV-9-2</p>
<p>INFO    2019-02-23 00:59:00     AddOrReplaceReadGroups  Processed     1,000,000 records.  Elapsed time: 00:00:33s.  Time for last 1,000,000:   33s.  L<br>ast read position: chr9:26,425,698<br>INFO    2019-02-23 00:59:34     AddOrReplaceReadGroups  Processed     2,000,000 records.  Elapsed time: 00:01:07s.  Time for last 1,000,000:   33s.  L<br>ast read position: chr5:38,200,263<br>INFO    2019-02-23 01:00:29     AddOrReplaceReadGroups  Processed     3,000,000 records.  Elapsed time: 00:02:02s.  Time for last 1,000,000:   55s.  L<br>ast read position: chr4:1,886,332<br>INFO    2019-02-23 01:00:56     AddOrReplaceReadGroups  Processed     4,000,000 records.  Elapsed time: 00:02:28s.  Time for last 1,000,000:   26s.  L<br>ast read position: chr5:6,379,073<br>INFO    2019-02-23 01:01:34     AddOrReplaceReadGroups  Processed     5,000,000 records.  Elapsed time: 00:03:07s.  Time for last 1,000,000:   38s.  L<br>ast read position: chr6:18,567,116<br>INFO    2019-02-23 01:02:13     AddOrReplaceReadGroups  Processed     6,000,000 records.  Elapsed time: 00:03:46s.  Time for last 1,000,000:   38s.  L<br>ast read position: chr9:39,573,973<br>INFO    2019-02-23 01:02:40     AddOrReplaceReadGroups  Processed     7,000,000 records.  Elapsed time: 00:04:13s.  Time for last 1,000,000:   27s.  L<br>ast read position: chr5:22,938,417<br>INFO    2019-02-23 01:03:19     AddOrReplaceReadGroups  Processed     8,000,000 records.  Elapsed time: 00:04:51s.  Time for last 1,000,000:   38s.  L<br>ast read position: chr4:23,545,960<br>INFO    2019-02-23 01:03:55     AddOrReplaceReadGroups  Processed     9,000,000 records.  Elapsed time: 00:05:28s.  Time for last 1,000,000:   36s.  L<br>ast read position: chr4:17,586,047<br>INFO    2019-02-23 01:04:24     AddOrReplaceReadGroups  Processed    10,000,000 records.  Elapsed time: 00:05:57s.  Time for last 1,000,000:   28s.  L<br>ast read position: chr7:21,260,263<br>INFO    2019-02-23 01:04:58     AddOrReplaceReadGroups  Processed    11,000,000 records.  Elapsed time: 00:06:31s.  Time for last 1,000,000:   33s.  L<br>ast read position: chr4:25,569,847<br>INFO    2019-02-23 01:05:36     AddOrReplaceReadGroups  Processed    12,000,000 records.  Elapsed time: 00:07:08s.  Time for last 1,000,000:   37s.  L<br>ast read position: chr4:25,075,124<br>INFO    2019-02-23 01:06:04     AddOrReplaceReadGroups  Processed    13,000,000 records.  Elapsed time: 00:07:36s.  Time for last 1,000,000:   28s.  L<br>ast read position: chr1:5,055,820<br>INFO    2019-02-23 01:06:38     AddOrReplaceReadGroups  Processed    14,000,000 records.  Elapsed time: 00:08:11s.  Time for last 1,000,000:   34s.  L<br>ast read position: chr5:40,818,516<br>INFO    2019-02-23 01:07:13     AddOrReplaceReadGroups  Processed    15,000,000 records.  Elapsed time: 00:08:46s.  Time for last 1,000,000:   34s.  L<br>ast read position: chr3:28,597,426<br>INFO    2019-02-23 01:07:40     AddOrReplaceReadGroups  Processed    16,000,000 records.  Elapsed time: 00:09:12s.  Time for last 1,000,000:   26s.  L<br>ast read position: chr2:52,066,083<br>INFO    2019-02-23 01:08:24     AddOrReplaceReadGroups  Processed    17,000,000 records.  Elapsed time: 00:09:54s.  Time for last 1,000,000:   41s.  L<br>ast read position: chr5:8,214,376<br>INFO    2019-02-23 01:08:53     AddOrReplaceReadGroups  Processed    18,000,000 records.  Elapsed time: 00:10:25s.  Time for last 1,000,000:   31s.  L<br>ast read position: chr2:42,040,926<br>INFO    2019-02-23 01:09:19     AddOrReplaceReadGroups  Processed    19,000,000 records.  Elapsed time: 00:10:52s.  Time for last 1,000,000:   26s.  L<br>ast read position: chr8:3,160,150<br>INFO    2019-02-23 01:09:59     AddOrReplaceReadGroups  Processed    20,000,000 records.  Elapsed time: 00:11:32s.  Time for last 1,000,000:   39s.  L<br>ast read position: chr9:2,765,258<br>INFO    2019-02-23 01:10:36     AddOrReplaceReadGroups  Processed    21,000,000 records.  Elapsed time: 00:12:08s.  Time for last 1,000,000:   36s.  L<br>ast read position: chr7:872,502<br>INFO    2019-02-23 01:11:13     AddOrReplaceReadGroups  Processed    22,000,000 records.  Elapsed time: 00:12:46s.  Time for last 1,000,000:   37s.  L<br>ast read position: chr5:38,922,782<br>INFO    2019-02-23 01:11:43     AddOrReplaceReadGroups  Processed    23,000,000 records.  Elapsed time: 00:13:15s.  Time for last 1,000,000:   29s.  L<br>ast read position: chr2:43,156,703<br>INFO    2019-02-23 01:12:10     AddOrReplaceReadGroups  Processed    24,000,000 records.  Elapsed time: 00:13:42s.  Time for last 1,000,000:   26s.  L<br>ast read position: chr2:42,168,429<br>INFO    2019-02-23 01:12:37     AddOrReplaceReadGroups  Processed    25,000,000 records.  Elapsed time: 00:14:10s.  Time for last 1,000,000:   27s.  L<br>ast read position: chr5:47,894,574<br>INFO    2019-02-23 01:13:05     AddOrReplaceReadGroups  Processed    26,000,000 records.  Elapsed time: 00:14:37s.  Time for last 1,000,000:   27s.  L<br>ast read position: chr5:47,836,828<br>INFO    2019-02-23 01:13:33     AddOrReplaceReadGroups  Processed    27,000,000 records.  Elapsed time: 00:15:05s.  Time for last 1,000,000:   27s.  L<br>ast read position: chr8:19,290,720<br>INFO    2019-02-23 01:14:01     AddOrReplaceReadGroups  Processed    28,000,000 records.  Elapsed time: 00:15:33s.  Time for last 1,000,000:   27s.  L<br>ast read position: chr5:17,045,282<br>INFO    2019-02-23 01:14:29     AddOrReplaceReadGroups  Processed    29,000,000 records.  Elapsed time: 00:16:02s.  Time for last 1,000,000:   28s.  L<br>ast read position: chr4:16,374,034<br>INFO    2019-02-23 01:14:56     AddOrReplaceReadGroups  Processed    30,000,000 records.  Elapsed time: 00:16:28s.  Time for last 1,000,000:   26s.  L<br>ast read position: chr2:51,915,818<br>INFO    2019-02-23 01:15:24     AddOrReplaceReadGroups  Processed    31,000,000 records.  Elapsed time: 00:16:57s.  Time for last 1,000,000:   28s.  L<br>ast read position: chr3:24,910,383<br>INFO    2019-02-23 01:15:55     AddOrReplaceReadGroups  Processed    32,000,000 records.  Elapsed time: 00:17:27s.  Time for last 1,000,000:   30s.  L<br>ast read position: chr7:12,459,410<br>INFO    2019-02-23 01:16:22     AddOrReplaceReadGroups  Processed    33,000,000 records.  Elapsed time: 00:17:54s.  Time for last 1,000,000:   26s.  L<br>ast read position: chr9:39,689,303<br>[Sat Feb 23 01:20:04 CST 2019] picard.sam.AddOrReplaceReadGroups done. Elapsed time: 21.69 minutes.<br>Runtime.totalMemory()=1004011520<br>To get help, see <a href="http://broadinstitute.github.io/picard/index.html#GettingHelp" target="_blank" rel="noopener">http://broadinstitute.github.io/picard/index.html#GettingHelp</a><br><strong>Exception in thread “main” java.lang.OutOfMemoryError: GC overhead limit exceeded</strong><br>        at java.util.Arrays.copyOfRange(Arrays.java:3664)<br>        at java.lang.String.<init>(String.java:207)<br>        at java.lang.String.substring(String.java:1969)<br>        at htsjdk.samtools.util.StringUtil.split(StringUtil.java:89)<br>        at htsjdk.samtools.SAMLineParser.parseLine(SAMLineParser.java:229)<br>        at htsjdk.samtools.SAMTextReader$RecordIterator.parseLine(SAMTextReader.java:268)<br>        at htsjdk.samtools.SAMTextReader$RecordIterator.next(SAMTextReader.java:255)<br>        at htsjdk.samtools.SAMTextReader$RecordIterator.next(SAMTextReader.java:228)<br>        at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:569)<br>        at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548)<br>        at picard.sam.AddOrReplaceReadGroups.doWork(AddOrReplaceReadGroups.java:182)<br>        at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:295)<br>        at picard.cmdline.PicardCommandLine.instanceMain(PicardCommandLine.java:103)<br>        at picard.cmdline.PicardCommandLine.main(PicardCommandLine.java:113)<br>        1       picard<br>        1</init></p>
<p>[Sat Feb 23 00:58:20 2019]<br>rule picard:<br>    input: star_2pass/OV-9-2Aligned.out.sam<br>    output: star_2pass/OV-9-2_rg_added_sorted.bam<br>    jobid: 0<br>    wildcards: sample=OV-9-2</p>
<p>INFO    2019-02-23 00:58:23     AddOrReplaceReadGroups  </p>
<p><strong><strong>**</strong></strong> NOTE: Picard’s command line syntax is changing.</p>
<hr>
<p><strong><strong>**</strong></strong> For more information, please see:<br><strong><strong>**</strong></strong> <a href="https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition)" target="_blank" rel="noopener">https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition)</a></p>
<hr>
<p><strong><strong>**</strong></strong> The command line looks like this in the new syntax:</p>
<hr>
<p><strong><strong>**</strong></strong>    AddOrReplaceReadGroups -I star_2pass/OV-9-2Aligned.out.sam -O star_2pass/OV-9-2_rg_added_sorted.bam -SO coordinate -RGID OV-9-2 -RGLB rn<br>a -RGPL illumina -RGPU hiseq -RGSM OV-9-2</p>
<hr>
<p>00:58:23.874 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home02/qizhengyang/anaconda3/share/picard-2.18.26-0/picard.jar!/<br>com/intel/gkl/native/libgkl_compression.so<br>[Sat Feb 23 00:58:23 CST 2019] AddOrReplaceReadGroups INPUT=star_2pass/OV-9-2Aligned.out.sam OUTPUT=star_2pass/OV-9-2_rg_added_sorted.bam SORT_ORDER=c<br>oordinate RGID=OV-9-2 RGLB=rna RGPL=illumina RGPU=hiseq RGSM=OV-9-2    VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX<br>_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false<br>[Sat Feb 23 00:58:23 CST 2019] Executing as qizhengyang@node21 on Linux 2.6.32-431.el6.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_121-b15; Deflater:<br> Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.18.26-SNAPSHOT<br>INFO    2019-02-23 00:58:27     AddOrReplaceReadGroups  Created read-group ID=OV-9-2 PL=illumina LB=rna SM=OV-9-2</p>
<p>INFO    2019-02-23 00:59:00     AddOrReplaceReadGroups  Processed     1,000,000 records.  Elapsed time: 00:00:33s.  Time for last 1,000,000:   33s.  L<br>ast read position: chr9:26,425,698<br>INFO    2019-02-23 00:59:34     AddOrReplaceReadGroups  Processed     2,000,000 records.  Elapsed time: 00:01:07s.  Time for last 1,000,000:   33s.  L<br>ast read position: chr5:38,200,263<br>INFO    2019-02-23 01:00:29     AddOrReplaceReadGroups  Processed     3,000,000 records.  Elapsed time: 00:02:02s.  Time for last 1,000,000:   55s.  L<br>ast read position: chr4:1,886,332<br>INFO    2019-02-23 01:00:56     AddOrReplaceReadGroups  Processed     4,000,000 records.  Elapsed time: 00:02:28s.  Time for last 1,000,000:   26s.  L<br>ast read position: chr5:6,379,073<br>INFO    2019-02-23 01:01:34     AddOrReplaceReadGroups  Processed     5,000,000 records.  Elapsed time: 00:03:07s.  Time for last 1,000,000:   38s.  L<br>ast read position: chr6:18,567,116<br>INFO    2019-02-23 01:02:13     AddOrReplaceReadGroups  Processed     6,000,000 records.  Elapsed time: 00:03:46s.  Time for last 1,000,000:   38s.  L<br>ast read position: chr9:39,573,973<br>INFO    2019-02-23 01:02:40     AddOrReplaceReadGroups  Processed     7,000,000 records.  Elapsed time: 00:04:13s.  Time for last 1,000,000:   27s.  L<br>ast read position: chr5:22,938,417<br>INFO    2019-02-23 01:03:19     AddOrReplaceReadGroups  Processed     8,000,000 records.  Elapsed time: 00:04:51s.  Time for last 1,000,000:   38s.  L<br>ast read position: chr4:23,545,960<br>INFO    2019-02-23 01:03:55     AddOrReplaceReadGroups  Processed     9,000,000 records.  Elapsed time: 00:05:28s.  Time for last 1,000,000:   36s.  L<br>ast read position: chr4:17,586,047<br>INFO    2019-02-23 01:04:24     AddOrReplaceReadGroups  Processed    10,000,000 records.  Elapsed time: 00:05:57s.  Time for last 1,000,000:   28s.  L<br>ast read position: chr7:21,260,263<br>INFO    2019-02-23 01:04:58     AddOrReplaceReadGroups  Processed    11,000,000 records.  Elapsed time: 00:06:31s.  Time for last 1,000,000:   33s.  L<br>ast read position: chr4:25,569,847<br>INFO    2019-02-23 01:05:36     AddOrReplaceReadGroups  Processed    12,000,000 records.  Elapsed time: 00:07:08s.  Time for last 1,000,000:   37s.  L<br>ast read position: chr4:25,075,124<br>INFO    2019-02-23 01:06:04     AddOrReplaceReadGroups  Processed    13,000,000 records.  Elapsed time: 00:07:36s.  Time for last 1,000,000:   28s.  L<br>ast read position: chr1:5,055,820<br>INFO    2019-02-23 01:06:38     AddOrReplaceReadGroups  Processed    14,000,000 records.  Elapsed time: 00:08:11s.  Time for last 1,000,000:   34s.  L<br>ast read position: chr5:40,818,516<br>INFO    2019-02-23 01:07:13     AddOrReplaceReadGroups  Processed    15,000,000 records.  Elapsed time: 00:08:46s.  Time for last 1,000,000:   34s.  L<br>ast read position: chr3:28,597,426<br>INFO    2019-02-23 01:07:40     AddOrReplaceReadGroups  Processed    16,000,000 records.  Elapsed time: 00:09:12s.  Time for last 1,000,000:   26s.  L<br>ast read position: chr2:52,066,083<br>INFO    2019-02-23 01:08:24     AddOrReplaceReadGroups  Processed    17,000,000 records.  Elapsed time: 00:09:54s.  Time for last 1,000,000:   41s.  L<br>ast read position: chr5:8,214,376<br>INFO    2019-02-23 01:08:53     AddOrReplaceReadGroups  Processed    18,000,000 records.  Elapsed time: 00:10:25s.  Time for last 1,000,000:   31s.  L<br>ast read position: chr2:42,040,926<br>INFO    2019-02-23 01:09:19     AddOrReplaceReadGroups  Processed    19,000,000 records.  Elapsed time: 00:10:52s.  Time for last 1,000,000:   26s.  L<br>ast read position: chr8:3,160,150<br>INFO    2019-02-23 01:09:59     AddOrReplaceReadGroups  Processed    20,000,000 records.  Elapsed time: 00:11:32s.  Time for last 1,000,000:   39s.  L<br>ast read position: chr9:2,765,258<br>INFO    2019-02-23 01:10:36     AddOrReplaceReadGroups  Processed    21,000,000 records.  Elapsed time: 00:12:08s.  Time for last 1,000,000:   36s.  L<br>ast read position: chr7:872,502<br>INFO    2019-02-23 01:11:13     AddOrReplaceReadGroups  Processed    22,000,000 records.  Elapsed time: 00:12:46s.  Time for last 1,000,000:   37s.  L<br>ast read position: chr5:38,922,782<br>INFO    2019-02-23 01:11:43     AddOrReplaceReadGroups  Processed    23,000,000 records.  Elapsed time: 00:13:15s.  Time for last 1,000,000:   29s.  L<br>ast read position: chr2:43,156,703<br>INFO    2019-02-23 01:12:10     AddOrReplaceReadGroups  Processed    24,000,000 records.  Elapsed time: 00:13:42s.  Time for last 1,000,000:   26s.  L<br>ast read position: chr2:42,168,429<br>INFO    2019-02-23 01:12:37     AddOrReplaceReadGroups  Processed    25,000,000 records.  Elapsed time: 00:14:10s.  Time for last 1,000,000:   27s.  L<br>ast read position: chr5:47,894,574<br>INFO    2019-02-23 01:13:05     AddOrReplaceReadGroups  Processed    26,000,000 records.  Elapsed time: 00:14:37s.  Time for last 1,000,000:   27s.  L<br>ast read position: chr5:47,836,828<br>INFO    2019-02-23 01:13:33     AddOrReplaceReadGroups  Processed    27,000,000 records.  Elapsed time: 00:15:05s.  Time for last 1,000,000:   27s.  L<br>ast read position: chr8:19,290,720<br>INFO    2019-02-23 01:14:01     AddOrReplaceReadGroups  Processed    28,000,000 records.  Elapsed time: 00:15:33s.  Time for last 1,000,000:   27s.  L<br>ast read position: chr5:17,045,282<br>INFO    2019-02-23 01:14:29     AddOrReplaceReadGroups  Processed    29,000,000 records.  Elapsed time: 00:16:02s.  Time for last 1,000,000:   28s.  L<br>ast read position: chr4:16,374,034<br>INFO    2019-02-23 01:14:56     AddOrReplaceReadGroups  Processed    30,000,000 records.  Elapsed time: 00:16:28s.  Time for last 1,000,000:   26s.  L<br>ast read position: chr2:51,915,818<br>INFO    2019-02-23 01:15:24     AddOrReplaceReadGroups  Processed    31,000,000 records.  Elapsed time: 00:16:57s.  Time for last 1,000,000:   28s.  L<br>ast read position: chr3:24,910,383<br>INFO    2019-02-23 01:15:55     AddOrReplaceReadGroups  Processed    32,000,000 records.  Elapsed time: 00:17:27s.  Time for last 1,000,000:   30s.  L<br>ast read position: chr7:12,459,410<br>INFO    2019-02-23 01:16:22     AddOrReplaceReadGroups  Processed    33,000,000 records.  Elapsed time: 00:17:54s.  Time for last 1,000,000:   26s.  L<br>ast read position: chr9:39,689,303<br>[Sat Feb 23 01:20:04 CST 2019] picard.sam.AddOrReplaceReadGroups done. Elapsed time: 21.69 minutes.<br>Runtime.totalMemory()=1004011520<br>To get help, see <a href="http://broadinstitute.github.io/picard/index.html#GettingHelp" target="_blank" rel="noopener">http://broadinstitute.github.io/picard/index.html#GettingHelp</a><br>Exception in thread “main” java.lang.OutOfMemoryError: GC overhead limit exceeded<br>        at java.util.Arrays.copyOfRange(Arrays.java:3664)<br>        at java.lang.String.<init>(String.java:207)<br>        at java.lang.String.substring(String.java:1969)<br>        at htsjdk.samtools.util.StringUtil.split(StringUtil.java:89)<br>        at htsjdk.samtools.SAMLineParser.parseLine(SAMLineParser.java:229)<br>        at htsjdk.samtools.SAMTextReader$RecordIterator.parseLine(SAMTextReader.java:268)<br>        at htsjdk.samtools.SAMTextReader$RecordIterator.next(SAMTextReader.java:255)<br>        at htsjdk.samtools.SAMTextReader$RecordIterator.next(SAMTextReader.java:228)<br>        at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:569)<br>        at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548)<br>        at picard.sam.AddOrReplaceReadGroups.doWork(AddOrReplaceReadGroups.java:182)<br>        at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:295)<br>        at picard.cmdline.PicardCommandLine.instanceMain(PicardCommandLine.java:103)<br>        at picard.cmdline.PicardCommandLine.main(PicardCommandLine.java:113)<br>Exception in thread “Thread-0” java.lang.OutOfMemoryError: GC overhead limit exceeded<br>        at java.util.Hashtable.<init>(Hashtable.java:190)<br>        at java.util.Hashtable.<init>(Hashtable.java:211)<br>        at java.util.Properties.<init>(Properties.java:148)<br>        at java.util.Properties.<init>(Properties.java:140)<br>        at java.util.logging.LogManager.reset(LogManager.java:1321)<br>        at java.util.logging.LogManager$Cleaner.run(LogManager.java:239)<br>Exception in thread “Thread-1” java.lang.OutOfMemoryError: GC overhead limit exceeded<br>        at sun.nio.fs.UnixFileAttributes.get(UnixFileAttributes.java:68)<br>        at sun.nio.fs.UnixFileSystemProvider.implDelete(UnixFileSystemProvider.java:227)<br>        at sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:103)<br>        at java.nio.file.Files.delete(Files.java:1126)<br>        at htsjdk.samtools.util.nio.DeleteOnExitPathHook.runHooks(DeleteOnExitPathHook.java:57)<br>        at htsjdk.samtools.util.nio.DeleteOnExitPathHook$$Lambda$34/780934299.run(Unknown Source)<br>        at java.lang.Thread.run(Thread.java:745)<br>[Sat Feb 23 01:20:54 2019]<br>Error in rule picard:<br>    jobid: 0<br>    output: star_2pass/OV-9-2_rg_added_sorted.bam</init></init></init></init></init></p>
<p>RuleException:<br>CalledProcessError in line 115 of /home02/qizhengyang/qizhengyang/gatk_rna/Snakefile:<br>Command ‘set -euo pipefail;  picard AddOrReplaceReadGroups I=star_2pass/OV-9-2Aligned.out.sam O=star_2pass/OV-9-2_rg_added_sorted.bam SO=coordinate RG<br>ID=OV-9-2 RGLB=rna RGPL=illumina RGPU=hiseq RGSM=OV-9-2’ returned non-zero exit status 1.<br>  File “/home02/qizhengyang/qizhengyang/gatk_rna/Snakefile”, line 115, in __rule_picard<br>  File “/home02/qizhengyang/anaconda3/lib/python3.6/concurrent/futures/thread.py”, line 56, in run<br>Removing output files of failed job picard since they might be corrupted:<br>star_2pass/OV-9-2_rg_added_sorted.bam<br>Shutting down, this might take some time.<br>Exiting because a job execution failed. Look above for error message<br>(END) </p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">snakemake -n --quiet</span><br><span class="line">snakemake --cluster "qsub -q low" --jobs 100</span><br><span class="line">pestat</span><br><span class="line"><span class="meta">#</span> 36 jobs, busy</span><br><span class="line"></span><br><span class="line">qstat -f | less</span><br></pre></td></tr></table></figure>
<p><img src="/images/1550891046764.png" alt="1550891046764"></p>
<p>一个终端与服务器连接终端</p>
<blockquote>
<p>Socket error Event: 32 Error: 10053.<br>Connection closing…Socket close.</p>
<p>Connection closed by foreign host.</p>
<p>Disconnected from remote host(qizhengyang) at 11:29:56.</p>
<p>Type `help’ to learn how to use Xshell prompt.<br>[C:~]$ </p>
</blockquote>
<p><code>last</code> 显示用户最近登录信息。<br><code>top</code>用于实时显示 process 的动态。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">snakemake -n -s Snakefile2 --quiet</span><br><span class="line"></span><br><span class="line">mv Snakefile Snakefile_temp_1</span><br><span class="line">mv Snakefile1 Snakefile_temp_2</span><br><span class="line">mv Snakefile2 Snakefile</span><br><span class="line"></span><br><span class="line">snakemake --unlock</span><br><span class="line">nohup snakemake --cluster "qsub -q low" --jobs 100 &amp;</span><br><span class="line"><span class="meta">#</span> 输出追加到"nohup.out"，nohup.out文件保留上次的信息</span><br></pre></td></tr></table></figure>
<blockquote>
<p>[qizhengyang@node1 gatk_rna]$ jobs<br>[1]+  Running                 nohup snakemake –cluster “qsub -q low” –jobs 100 &amp;<br>[qizhengyang@node1 gatk_rna]$ ps aux | grep snakemake | grep -v grep<br>528      39349  0.5  0.0 289360 26440 pts/5    Sl   14:00   0:01 /home02/qizhengyang/anaconda3/bin/python3.6 /home02/qizhengyang/anaconda3/bin/snakemake –cluster qsub -q low –jobs 100</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ll -h nohup.out</span><br></pre></td></tr></table></figure>
<p>一个 picard job 出现错误 Exception in thread “main” java.lang.OutOfMemoryError: GC overhead limit exceeded</p>
<blockquote>
<p>Moreover, now i am running command like /usr/bin/java -Xmx40g -jar /usr/local/picard-tools-1.129/picard.jar …., and it’s working. Regards, Ravi.</p>
</blockquote>
<blockquote>
<p>ava刚刚出现的年代，有一个相比于其他语言的优势就是，内存回收机制。不需要明确的调用释放内存的API，java就自动完成，这个过程就是Garbage Collection，简称GC。</p>
<p>其实还是有一个终极方法的，而且是治标治本的方法，就是找到占用内存大的地方，把代码优化了，就不会出现这个问题了。</p>
</blockquote>
<blockquote>
<p>Building DAG of jobs…<br>Using shell: /bin/bash<br>Provided cores: 96<br>Rules claiming more threads will be scaled down.<br>Job counts:<br>        count   jobs<br>        1       picard<br>        1</p>
<p>[Sat Feb 23 14:00:10 2019]<br>rule picard:<br>    input: star_2pass/HB-9-2Aligned.out.sam<br>    output: star_2pass/HB-9-2_rg_added_sorted.bam<br>    jobid: 0<br>    wildcards: sample=HB-9-2</p>
<p>INFO    2019-02-23 14:00:12     AddOrReplaceReadGroups  </p>
<p><strong><strong>**</strong></strong> NOTE: Picard’s command line syntax is changing.</p>
<hr>
<p><strong><strong>**</strong></strong> For more information, please see:<br><strong><strong>**</strong></strong> <a href="https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition)" target="_blank" rel="noopener">https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition)</a></p>
<hr>
<p><strong><strong>**</strong></strong> The command line looks like this in the new syntax:</p>
<hr>
<p><strong><strong>**</strong></strong>    AddOrReplaceReadGroups -I star_2pass/HB-9-2Aligned.out.sam -O star_2pass/HB-9-2_rg_added_sorted.bam -SO coordinate -RGID HB-9-2 -RGLB rna -RGPL illumina -RGPU hiseq -RGSM HB-9-2</p>
<hr>
<p>14:00:12.937 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home02/qizhengyang/anaconda3/share/picard-2.18.26-0/picard.jar!/com/intel/gkl/native/libgkl_compression.so<br>[Sat Feb 23 14:00:13 CST 2019] AddOrReplaceReadGroups INPUT=star_2pass/HB-9-2Aligned.out.sam OUTPUT=star_2pass/HB-9-2_rg_added_sorted.bam SORT_ORDER=coordinate RGID=HB-9-2 RGLB=rna RGPL=illumina RGPU=hiseq RGSM=HB-9-2    VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false<br>[Sat Feb 23 14:00:13 CST 2019] Executing as qizhengyang@node21 on Linux 2.6.32-431.el6.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_121-b15; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.18.26-SNAPSHOT<br>INFO    2019-02-23 14:00:20     AddOrReplaceReadGroups  Created read-group ID=HB-9-2 PL=illumina LB=rna SM=HB-9-2</p>
<p>INFO    2019-02-23 14:00:58     AddOrReplaceReadGroups  Processed     1,000,000 records.  Elapsed time: 00:00:37s.  Time for last 1,000,000:   37s.  Last read position: chr1:10,583,000<br>[Sat Feb 23 14:07:47 CST 2019] picard.sam.AddOrReplaceReadGroups done. Elapsed time: 7.58 minutes.<br>Runtime.totalMemory()=999292928<br>To get help, see <a href="http://broadinstitute.github.io/picard/index.html#GettingHelp" target="_blank" rel="noopener">http://broadinstitute.github.io/picard/index.html#GettingHelp</a><br><strong>Exception in thread “main” java.lang.OutOfMemoryError: GC overhead limit exceeded</strong><br>        at java.util.Arrays.copyOfRange(Arrays.java:3664)<br>        at java.lang.String.<init>(String.java:207)<br>        at java.io.BufferedReader.readLine(BufferedReader.java:356)<br>        at java.io.LineNumberReader.readLine(LineNumberReader.java:201)<br>        at htsjdk.samtools.util.BufferedLineReader.readLine(BufferedLineReader.java:68)<br>        at htsjdk.samtools.SAMTextReader.advanceLine(SAMTextReader.java:221)<br>        at htsjdk.samtools.SAMTextReader.access$800(SAMTextReader.java:37)<br>        at htsjdk.samtools.SAMTextReader$RecordIterator.next(SAMTextReader.java:257)<br>        at htsjdk.samtools.SAMTextReader$RecordIterator.next(SAMTextReader.java:228)<br>        at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:569)<br>        at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548)<br>        at picard.sam.AddOrReplaceReadGroups.doWork(AddOrReplaceReadGroups.java:182)<br>        at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:295)<br>        at picard.cmdline.PicardCommandLine.instanceMain(PicardCommandLine.java:103)<br>        at picard.cmdline.PicardCommandLine.main(PicardCommandLine.java:113)<br>Exception in thread “Thread-1” java.lang.OutOfMemoryError: GC overhead limit exceeded<br>        at sun.nio.fs.UnixFileAttributes.get(UnixFileAttributes.java:68)<br>        at sun.nio.fs.UnixFileSystemProvider.implDelete(UnixFileSystemProvider.java:227)<br>        at sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:103)<br>        at java.nio.file.Files.delete(Files.java:1126)<br>        at htsjdk.samtools.util.nio.DeleteOnExitPathHook.runHooks(DeleteOnExitPathHook.java:57)<br>        at htsjdk.samtools.util.nio.DeleteOnExitPathHook$$Lambda$34/780934299.run(Unknown Source)<br>        at java.lang.Thread.run(Thread.java:745)<br>[Sat Feb 23 14:09:07 2019]<br>Error in rule picard:<br>    jobid: 0<br>    output: star_2pass/HB-9-2_rg_added_sorted.bam</init></p>
<p>RuleException:<br>CalledProcessError in line 115 of /home02/qizhengyang/qizhengyang/gatk_rna/Snakefile:<br>Command ‘set -euo pipefail;  picard AddOrReplaceReadGroups I=star_2pass/HB-9-2Aligned.out.sam O=star_2pass/HB-9-2_rg_added_sorted.bam SO=coordinate RGID=HB-9-2 RGLB=rna RGPL=illumina RGPU=hiseq RGSM=HB-9-2’ returned non-zero exit status 1.<br>  File “/home02/qizhengyang/qizhengyang/gatk_rna/Snakefile”, line 115, in __rule_picard<br>  File “/home02/qizhengyang/anaconda3/lib/python3.6/concurrent/futures/thread.py”, line 56, in run<br><strong>Removing output files of failed job picard since they might be corrupted:</strong><br>star_2pass/HB-9-2_rg_added_sorted.bam<br>Shutting down, this might take some time.<br>Exiting because a job execution failed. Look above for error message<br>(END) </p>
</blockquote>
<blockquote>
<p>[qizhengyang@node1 gatk_rna]$ snakemake -n –quiet<br>Job counts:<br>count    jobs<br>1    all<br>36    gatk<br>36    gatk_filter<br>16    gatk_split<br>1    picard<br>13    picard_markduplicat</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">snakemake --unlock</span><br><span class="line">nohup snakemake --cluster &quot;qsub -q low&quot; --jobs 100 &amp;</span><br></pre></td></tr></table></figure>
<p>解决办法</p>
<ol>
<li><p>查看 picard.jar 的路径</p>
</li>
<li><p>设置环境变量 export picard=/home02/qizhengyang/anaconda3/share/picard-2.18.26-0/picard.jar，</p>
<p>写入 ~/.bash_profile，source</p>
</li>
<li><p>设置JVM最大可用内存为40g，java -Xmx40g -jar $picard。<a href="https://github.com/bioconda/bioconda-recipes/blob/master/recipes/picard/picard.sh" target="_blank" rel="noopener">默认是1G</a></p>
</li>
</ol>
<blockquote>
<p>[qizhengyang@node1 gatk_rna]$ find ~ -name picard.jar<br>/home02/qizhengyang/anaconda3/share/picard-2.18.26-0/picard.jar<br>/home02/qizhengyang/anaconda3/pkgs/picard-2.18.26-0/share/picard-2.18.26-0/picard.jar</p>
</blockquote>
<p>查看当前环境变量 <code>export | less</code></p>
<blockquote>
<p>980879.node1               …b.gatk.202.sh qizhengyang     01:31:52 R low<br>980880.node1               …b.gatk.182.sh qizhengyang     01:31:40 R low<br>980881.node1               …b.gatk.204.sh qizhengyang     01:31:11 R low<br>980882.node1               …b.gatk.209.sh qizhengyang     01:31:20 R low<br>980884.node1               …b.gatk.214.sh qizhengyang     01:31:59 R low<br>980888.node1               …b.gatk.187.sh qizhengyang     01:30:53 R low<br>980889.node1               …b.gatk.210.sh qizhengyang     01:30:29 R low<br>980891.node1               …b.gatk.186.sh qizhengyang     01:31:41 R low<br>980892.node1               …b.gatk.216.sh qizhengyang     01:30:55 R low<br>980893.node1               …b.gatk.206.sh qizhengyang     01:31:36 R low<br>980894.node1               …b.gatk.192.sh qizhengyang     01:30:59 R low<br>980896.node1               …b.gatk.188.sh qizhengyang     01:31:45 R low<br>980898.node1               …b.gatk.215.sh qizhengyang     01:31:05 R low<br>980899.node1               …_split.167.sh qizhengyang     06:39:52 R low<br>980900.node1               …b.gatk.200.sh qizhengyang     01:31:05 R low<br>980901.node1               …_split.153.sh qizhengyang     05:35:11 R low<br>980902.node1               …b.gatk.201.sh qizhengyang     01:31:57 R low<br>980903.node1               …b.gatk.195.sh qizhengyang     01:29:26 R low<br>980904.node1               …b.gatk.197.sh qizhengyang     01:29:35 R low<br>980905.node1               …b.gatk.185.sh qizhengyang     01:30:31 R low<br>980909.node1               …_split.160.sh qizhengyang     05:36:38 R low<br>980910.node1               …b.gatk.198.sh qizhengyang     01:29:47 R low<br>980912.node1               …b.gatk.193.sh qizhengyang     01:30:22 R low<br>980913.node1               …_split.155.sh qizhengyang     04:15:22 R low<br>980914.node1               …_split.175.sh qizhengyang     04:04:21 R low<br>980915.node1               …_split.172.sh qizhengyang     03:43:49 R low<br>980916.node1               …_split.177.sh qizhengyang     03:22:15 R low<br>980917.node1               …_split.147.sh qizhengyang     05:08:37 R low<br>980918.node1               …_split.158.sh qizhengyang     05:14:32 R low<br>980919.node1               …_split.176.sh qizhengyang     04:49:57 R low<br>980920.node1               …_split.163.sh qizhengyang     04:37:11 R low<br>980921.node1               …_split.171.sh qizhengyang     04:17:19 R low<br>980922.node1               …_split.154.sh qizhengyang     04:05:50 R low<br>980923.node1               …_split.148.sh qizhengyang     03:46:37 R low<br>980925.node1               …_split.181.sh qizhengyang     03:25:10 R low<br>980926.node1               …_split.169.sh qizhengyang     02:20:52 R low        </p>
</blockquote>
<h4 id="任务完成"><a href="#任务完成" class="headerlink" title="任务完成"></a>任务完成</h4><blockquote>
<p>[Sun Feb 24 23:55:12 2019]<br>Finished job 0.<br>103 of 103 steps (100%) done<br>Complete log: /home02/qizhengyang/qizhengyang/gatk_rna/.snakemake/log/2019-02-23T214006.459737.snakemake.log</p>
</blockquote>
<h5 id="最终的Snakefile"><a href="#最终的Snakefile" class="headerlink" title="最终的Snakefile"></a>最终的Snakefile</h5><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2019-2-19 10:28:52 part</span></span><br><span class="line"><span class="comment"># GATK snakemake</span></span><br><span class="line"><span class="comment"># qizhengyang</span></span><br><span class="line"></span><br><span class="line">from os.path import join</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">GENOME = 'genome/HWB.chromosome.fa'</span><br><span class="line">GTF = 'genes/HWB.gene.models.gtf'</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(SAMPLES,) = glob_wildcards('pairedDIR/&#123;sample&#125;_1P.fq.gz')</span><br><span class="line">PATTERN_R1 = join('pairedDIR', '&#123;sample&#125;_1P.fq.gz')</span><br><span class="line">PATTERN_R2 = join('pairedDIR', '&#123;sample&#125;_2P.fq.gz')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">rule all:</span><br><span class="line">    input:</span><br><span class="line">        'star_index_2pass/',</span><br><span class="line">        expand('star_1pass/&#123;sample&#125;SJ.out.tab', sample=SAMPLES),</span><br><span class="line">        'star_index_2pass/',</span><br><span class="line">        expand('star_2pass/&#123;sample&#125;Aligned.out.sam', sample=SAMPLES),</span><br><span class="line">        expand('star_2pass/&#123;sample&#125;_rg_added_sorted.bam', sample=SAMPLES),</span><br><span class="line">        expand('star_2pass/&#123;sample&#125;_dedup.bam', sample=SAMPLES),</span><br><span class="line">        expand('star_2pass/&#123;sample&#125;_dedup_split.bam', sample=SAMPLES),</span><br><span class="line">        expand('star_2pass/&#123;sample&#125;.vcf', sample=SAMPLES),</span><br><span class="line">        expand('star_2pass/&#123;sample&#125;_filtered.vcf', sample=SAMPLES)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">rule star_index:</span><br><span class="line">    input:</span><br><span class="line">        genome = GENOME,</span><br><span class="line">        gtf = GTF</span><br><span class="line">    output:</span><br><span class="line">        star_index = directory('star_index/')</span><br><span class="line"></span><br><span class="line">    log:</span><br><span class="line">        'star_index.log'</span><br><span class="line">    threads: 20</span><br><span class="line">    run:</span><br><span class="line">        <span class="comment"># star 1-pass index, OK</span></span><br><span class="line">        shell('STAR --runThreadN &#123;threads&#125; --runMode genomeGenerate'</span><br><span class="line">              ' --genomeDir &#123;output.star_index&#125;'</span><br><span class="line">              ' --genomeFastaFiles &#123;input.genome&#125;'</span><br><span class="line">              ' --sjdbGTFfile &#123;input.gtf&#125;'</span><br><span class="line">              ' 2&gt; &#123;log&#125;')</span><br><span class="line"></span><br><span class="line">rule star_1pass_align:</span><br><span class="line">    input:</span><br><span class="line">        index = 'star_index/',</span><br><span class="line">        r1 = PATTERN_R1,</span><br><span class="line">        r2 = PATTERN_R2</span><br><span class="line">    output:</span><br><span class="line">        index = 'star_1pass/&#123;sample&#125;SJ.out.tab'</span><br><span class="line">    threads: 20</span><br><span class="line">    params:</span><br><span class="line">        prefix = './star_1pass/&#123;sample&#125;'</span><br><span class="line">    <span class="comment"># 在使用params之前是报错的，NameError,The name 'sample' is unknown in this context</span></span><br><span class="line">    run:</span><br><span class="line">        <span class="comment"># star 1-pass align, OK</span></span><br><span class="line">        shell('STAR --runThreadN &#123;threads&#125; --genomeDir &#123;input.index&#125;'</span><br><span class="line">              ' --readFilesIn &#123;input.r1&#125; &#123;input.r2&#125;'</span><br><span class="line">              ' --readFilesCommand zcat'</span><br><span class="line">              ' --outFileNamePrefix &#123;params.prefix&#125;')</span><br><span class="line"></span><br><span class="line">rule star_2pass_index:</span><br><span class="line">    input:</span><br><span class="line">        genome = GENOME,</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 这里必需加expand，不然会报错：Wildcards in input files cannot be determined from output files:</span></span><br><span class="line">        <span class="comment"># 'sample'。</span></span><br><span class="line">        <span class="comment"># 很奇怪，确实是需要所有样本的剪接位点信息，我之前没有注意到。。感谢报错</span></span><br><span class="line">        <span class="comment"># 然后用--sjdbFileChrStartEnd参数将所有样品的SJ.out.tab文件作为输入的annotated junction进行第二次建index</span></span><br><span class="line">        <span class="comment"># http://www.bioinfo-scrounger.com/archives/288</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 这里不能加三个引号（"""或'''注释）</span></span><br><span class="line"></span><br><span class="line">        splice_site = expand('star_1pass/&#123;sample&#125;SJ.out.tab', sample=SAMPLES)</span><br><span class="line">    output:</span><br><span class="line">        index = directory('star_index_2pass/')</span><br><span class="line">    threads: 20</span><br><span class="line">    run:</span><br><span class="line">        <span class="comment"># star 2-pass index, OK</span></span><br><span class="line">        shell('STAR --runThreadN &#123;threads&#125; --runMode genomeGenerate'</span><br><span class="line">              ' --genomeDir &#123;output.index&#125;'</span><br><span class="line">              ' --genomeFastaFiles &#123;input.genome&#125;'</span><br><span class="line">              ' --sjdbFileChrStartEnd &#123;input.splice_site&#125;')</span><br><span class="line"></span><br><span class="line">rule star_2pass_align:</span><br><span class="line">    input:</span><br><span class="line">        index = 'star_index_2pass/',</span><br><span class="line">        r1 = PATTERN_R1,</span><br><span class="line">        r2 = PATTERN_R2</span><br><span class="line">    output:</span><br><span class="line">        sam = 'star_2pass/&#123;sample&#125;Aligned.out.sam'</span><br><span class="line">    threads: 20</span><br><span class="line">    params:</span><br><span class="line">        prefix = 'star_2pass/&#123;sample&#125;'</span><br><span class="line">    run:</span><br><span class="line">        <span class="comment"># star 2-pass align</span></span><br><span class="line">        shell('STAR --runThreadN &#123;threads&#125; --genomeDir &#123;input.index&#125;'</span><br><span class="line">              ' --readFilesIn &#123;input.r1&#125; &#123;input.r2&#125;'</span><br><span class="line">              ' --readFilesCommand zcat'</span><br><span class="line">              ' --outFileNamePrefix &#123;params.prefix&#125;')</span><br><span class="line"></span><br><span class="line">rule picard:</span><br><span class="line">    input:</span><br><span class="line">        sam = 'star_2pass/&#123;sample&#125;Aligned.out.sam'</span><br><span class="line">    output:</span><br><span class="line">        bam = 'star_2pass/&#123;sample&#125;_rg_added_sorted.bam'</span><br><span class="line">    run:</span><br><span class="line">        <span class="comment"># RGID和RGSM的sample必须是&#123;wildcards.sample&#125;，不然</span></span><br><span class="line">        <span class="comment"># The name 'sample' is unknown in this context. Please make sure that you defined that variable.</span></span><br><span class="line">        <span class="comment"># Also note that braces not used for variable access have to be escaped by repeating them, i.e. &#123;&#123;print $1&#125;&#125;</span></span><br><span class="line">        shell('java -Xmx40g -jar $picard AddOrReplaceReadGroups'</span><br><span class="line">              ' I=&#123;input.sam&#125;'</span><br><span class="line">              ' O=&#123;output.bam&#125;'</span><br><span class="line">              ' SO=coordinate'</span><br><span class="line">              ' RGID=&#123;wildcards.sample&#125;'</span><br><span class="line">              ' RGLB=rna'</span><br><span class="line">              ' RGPL=illumina'</span><br><span class="line">              ' RGPU=hiseq'</span><br><span class="line">              ' RGSM=&#123;wildcards.sample&#125;')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">rule picard_markduplicates:</span><br><span class="line">    input:</span><br><span class="line">        bam = 'star_2pass/&#123;sample&#125;_rg_added_sorted.bam'</span><br><span class="line">    output:</span><br><span class="line">        dedup_bam = 'star_2pass/&#123;sample&#125;_dedup.bam'</span><br><span class="line">    params:</span><br><span class="line">        dedup_metrices = 'star_2pass/&#123;sample&#125;_dedup.metrics'</span><br><span class="line">    run:</span><br><span class="line">        shell('java -Xmx40g -jar $picard MarkDuplicates'</span><br><span class="line">              ' I=&#123;input.bam&#125;'</span><br><span class="line">              ' O=&#123;output.dedup_bam&#125;'</span><br><span class="line">              ' CREATE_INDEX=true'</span><br><span class="line">              ' VALIDATION_STRINGENCY=SILENT'</span><br><span class="line">              ' M=&#123;params.dedup_metrices&#125;')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">rule gatk_split:</span><br><span class="line">    input:</span><br><span class="line">        dedup_bam = 'star_2pass/&#123;sample&#125;_dedup.bam',</span><br><span class="line">        genome = GENOME</span><br><span class="line">    output:</span><br><span class="line">        split_bam = 'star_2pass/&#123;sample&#125;_dedup_split.bam'</span><br><span class="line">    run:</span><br><span class="line">        shell('java -Xmx10g -jar $GATK -T SplitNCigarReads'</span><br><span class="line">              ' -R &#123;input.genome&#125;'</span><br><span class="line">              ' -I &#123;input.dedup_bam&#125;'</span><br><span class="line">              ' -o &#123;output.split_bam&#125;'</span><br><span class="line">              ' -rf ReassignOneMappingQuality'</span><br><span class="line">              ' -RMQF 255'</span><br><span class="line">              ' -RMQT 60'</span><br><span class="line">              ' -U ALLOW_N_CIGAR_READS')</span><br><span class="line">rule gatk:</span><br><span class="line">    input:</span><br><span class="line">        bam = 'star_2pass/&#123;sample&#125;_dedup_split.bam',</span><br><span class="line">        genome = GENOME</span><br><span class="line">    output:</span><br><span class="line">        vcf = 'star_2pass/&#123;sample&#125;.vcf'</span><br><span class="line">    run:</span><br><span class="line">        shell('java -Xmx10g -jar $GATK -T HaplotypeCaller'</span><br><span class="line">              ' -R &#123;input.genome&#125;'</span><br><span class="line">              ' -I &#123;input.bam&#125;'</span><br><span class="line">              ' -dontUseSoftClippedBases'</span><br><span class="line">              ' -stand_call_conf 20.0'</span><br><span class="line">              ' -o &#123;output.vcf&#125;')</span><br><span class="line"></span><br><span class="line">rule gatk_filter:</span><br><span class="line">    input:</span><br><span class="line">        genome = GENOME,</span><br><span class="line">        vcf = 'star_2pass/&#123;sample&#125;.vcf'</span><br><span class="line">    output:</span><br><span class="line">        'star_2pass/&#123;sample&#125;_filtered.vcf'</span><br><span class="line">    run:</span><br><span class="line">        shell('java -Xmx10g -jar $GATK '</span><br><span class="line">              ' -T VariantFiltration'</span><br><span class="line">              ' -R &#123;input.genome&#125;'</span><br><span class="line">              ' -V &#123;input.vcf&#125;'</span><br><span class="line">              ' -window 35'</span><br><span class="line">              ' -cluster 3'</span><br><span class="line">              ' -filterName FS -filter <span class="string">"FS &gt; 30.0"</span>'</span><br><span class="line">              ' -filterName QD -filter <span class="string">"QD &lt; 2.0"</span>'</span><br><span class="line">              ' -o &#123;output&#125;')</span><br></pre></td></tr></table></figure>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="https://adoubi.life/posts/2017-11-14/" target="_blank" rel="noopener">利用snakemake搭建流程简明教程</a></li>
<li><a href="https://snakemake.readthedocs.io/en/latest/executable.html?highlight=cluster" target="_blank" rel="noopener">snakemake docs</a></li>
<li><a href="https://github.com/slowkow/snakefiles/pull/1/files" target="_blank" rel="noopener">RNAseq variant calling pipeline </a></li>
<li><a href="https://slowkow.com/notes/snakemake-tutorial/#1-installing-snakemake" target="_blank" rel="noopener">Build bioinformatics pipelines with Snakemake</a></li>
<li><a href="https://github.com/slowkow/snakefiles/blob/master/kallisto/Snakefile" target="_blank" rel="noopener">kallisto-snakefiles</a></li>
<li><a href="http://pedagogix-tagc.univ-mrs.fr/courses/ABD/practical/snakemake/snake_intro.html" target="_blank" rel="noopener">Writing a RNA-Seq workflow with snakemake</a></li>
<li><a href="https://www.cmwonderland.com/2018/05/05/snakemake/" target="_blank" rel="noopener">snakemake初步</a></li>
<li><a href="https://www.jianshu.com/p/b400dc7c5eea" target="_blank" rel="noopener">RNA-seq 检测变异之 GATK 最佳实践流程</a></li>
<li><a href="https://github.com/leipzig/snakemake-example/blob/master/Snakefile" target="_blank" rel="noopener">snakemake-example</a></li>
<li><a href="https://www.jianshu.com/p/8e57fd2b81b2" target="_blank" rel="noopener">我最喜欢的流程管理工具</a></li>
</ol>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://qizhengyang2017.github.io/2019/02/11/the-machine-stops/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qizhengyang">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/11/the-machine-stops/" itemprop="url">
                  the machine stops
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-11 21:08:49 / Modified: 21:19:47" itemprop="dateCreated datePublished" datetime="2019-02-11T21:08:49+08:00">2019-02-11</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>从工业革命开始，城市化，信息化，智能化，人们的生活发生了不可逆转的剧变。有些东西消失后就不会再出现，比如蒸汽机车，有些东西即使外界再变也不会消失，比如文明。</p>
<p><img src="/images/machinestops.PNG" alt=""></p>
<blockquote>
<p>they have given up, to a great extent, the amenities and achievements of civilization: solitude and leisure, the sanction to be oneself, truly absorbed, whether in contemplating a work of art, a scientific theory, a sunset, or the face of one’s beloved.</p>
</blockquote>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://qizhengyang2017.github.io/2019/01/30/甲基化数据分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qizhengyang">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/30/甲基化数据分析/" itemprop="url">
                  甲基化数据分析
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-01-30 20:02:19 / Modified: 20:06:55" itemprop="dateCreated datePublished" datetime="2019-01-30T20:02:19+08:00">2019-01-30</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>DNA甲基化数据分析流程</p>
<ul>
<li>用Trimmomatic去除低质量序列（q&lt;20），接头。 </li>
<li>用BSMAP比对，允许0.8的错配率。</li>
<li>用methratio.py提取甲基化比例，选项-r去除PCR重复。</li>
</ul>
<p>获得DMR</p>
<ul>
<li>为了得到可靠的DMR区域，合并两个生物学重复，仅考虑所有文库中深度至少为4的胞嘧啶。</li>
<li>使用200bp窗口（50bp步长）识别DMR。</li>
<li>对每个窗口内的甲基化和未甲基化胞嘧啶进行Fisher精确检验。使用Benjamini-Hochberg对p值进行调整，估计错误发生率（FDR）。</li>
<li>FDR&lt;0.01，甲基化水平变化大于1.5倍且至少含有5个差异甲基化胞嘧啶（DMCs：Fisher精确检验中p&lt;0.01）的窗口用于进一步分析，窗口在100bp内合并为更大的区域。</li>
</ul>
<p>RNA-seq 数据分析</p>
<ul>
<li>Trimmomatic去除低质量序列和接头</li>
<li>用STAR进行比对，–sjdbGTFfile 用于提供基因组注释文件</li>
<li>htseq-count计算每个基因map上的片段数</li>
<li>DESeq2计算差异表达基因</li>
</ul>
<p>DMR-associated基因分析</p>
<ul>
<li>DMR相关基因定义为2kb启动子区域内具有DMR的基因</li>
<li><strong>仅用DMR-associated genes进行基因聚类</strong></li>
<li>差异基因定义，FPKM &gt;= 1, FDR &lt;= 0.01, fc &gt;= 1.5</li>
</ul>
<p>GO注释</p>
<ul>
<li>使用拟南芥（TAIR10）、番茄（ITAG3）、草莓（PhytozomeV12）的蛋白序列和GO注释文件</li>
<li>blast</li>
<li>用GOATOOLs进行GO富集</li>
</ul>
<p>小RNA分析</p>
<ul>
<li>使用BWA比对</li>
<li>计算DMR的24 nt 小RNA丰度（normalized to per million per one hundred base pair）</li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://qizhengyang2017.github.io/2019/01/29/Mysql使用过程中遇到的一些/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qizhengyang">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/29/Mysql使用过程中遇到的一些/" itemprop="url">
                  Mysql使用过程中遇到的一些问题
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-01-29 22:55:40" itemprop="dateCreated datePublished" datetime="2019-01-29T22:55:40+08:00">2019-01-29</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-01-31 12:04:45" itemprop="dateModified" datetime="2019-01-31T12:04:45+08:00">2019-01-31</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>blast2go本地化需要用到mysql，操作系统Centos 7。</p>
<h2 id="1-卸载之前的mysql"><a href="#1-卸载之前的mysql" class="headerlink" title="1. 卸载之前的mysql"></a>1. 卸载之前的mysql</h2><p>之前的版本是mysql5.6，想要更新到mysql5.7。</p>
<ol>
<li><p>查看mysql安装了哪些东西。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa |grep -i mysql</span><br></pre></td></tr></table></figure>
<p><img src="/images/mysql/rpmcheck.PNG" alt=""></p>
</li>
</ol>
<ol start="2">
<li><p>开始卸载</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum remove XXX</span><br></pre></td></tr></table></figure>
<p><img src="/images/mysql/remove.PNG" alt=""></p>
</li>
</ol>
<ol start="3">
<li><p>查看卸载是否完成</p>
</li>
<li><p>查找mysql相关目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find / -name mysql</span><br></pre></td></tr></table></figure>
<p><img src="/images/mysql/find.PNG" alt=""></p>
</li>
</ol>
<ol start="5">
<li><p>删除相关目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rm -rf XXX</span><br><span class="line">rm -rf /etc/my.cnf</span><br><span class="line">rm -rf rm -rf /var/log/mysqld.log</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="2-安装Mysql5-7"><a href="#2-安装Mysql5-7" class="headerlink" title="2. 安装Mysql5.7"></a>2. 安装Mysql5.7</h2><ol>
<li><p>安装mysql源</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm</span><br><span class="line">yum localinstall mysql57-community-release-el7-11.noarch.rpm</span><br><span class="line"># 检查是否安装成功</span><br><span class="line">yum repolist enabled | grep &quot;mysql.*-community.*&quot;</span><br></pre></td></tr></table></figure>
<p><img src="/images/mysql/install.PNG" alt=""></p>
</li>
</ol>
<ol start="2">
<li><p>启动mysql服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start mysqld</span><br><span class="line"># 查看状态</span><br><span class="line">systemctl status mysqld</span><br></pre></td></tr></table></figure>
<p>这里可能会遇到 “Another mysqld server running on port 3306 error”，可以采用<code>netstat -lp | grep 3306</code> 查找占用这个端口号的进程，kill 这个PID。（我发现占用这个3306的是mysql??）。</p>
</li>
<li><p>修改root密码</p>
<p>我用root身份导入数据的时候，提示我要修改密码。生成的默认密码在 <code>/var/log/mysqld.log</code> 文件中。使用 grep 命令找到日志中的密码。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep &apos;temporary password&apos; /var/log/mysqld.log</span><br></pre></td></tr></table></figure>
<p><img src="/images/mysql/password&#39;.PNG" alt=""></p>
</li>
</ol>
   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt;ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;123,c%vPl9ek&apos;;</span><br></pre></td></tr></table></figure>
<p>   或者：</p>
   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; use mysql;</span><br><span class="line">mysql&gt; update mysql.user set authentication_string=password(&apos;123,c%vPl9ek&apos;) where user=&apos;root&apos;;</span><br><span class="line">mysql&gt; flush privileges;</span><br></pre></td></tr></table></figure>
<h2 id="3-导入数据"><a href="#3-导入数据" class="headerlink" title="3. 导入数据"></a>3. 导入数据</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p &lt; b2gdb.sql</span><br></pre></td></tr></table></figure>
<p>会出现莫名其妙的错误，“ERROR 1819 (HY000) at line 4: Your password does not satisfy the current policy requirements”，但是我的密码是符合它的规则的。最后采取的办法是把检验密码的插件删了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt;uninstall plugin validate_password;</span><br></pre></td></tr></table></figure>
<p>有试着导入数据，这次的错误是：</p>
<p>“ERROR 1101 (42000) at line 9: BLOB, TEXT, GEOMETRY or JSON column ‘description’ can’t have a default value”</p>
<p>先查看了sql_mode</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select @@session.sql_mode;</span><br><span class="line">mysql&gt; select @@global.sql_mode;</span><br></pre></td></tr></table></figure>
<p><img src="/images/mysql/sql_mode.PNG" alt=""></p>
<p>之后重新设置sql_mode</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set sql_mode=&apos;&apos;;</span><br><span class="line">set global sql_mode=&apos;&apos;;</span><br></pre></td></tr></table></figure>
<p>重新打开一个终端，进入mysql，查看sql_mode</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select @@global.sql_mode;</span><br></pre></td></tr></table></figure>
<p>在尝试导入数据，成功。</p>
<h2 id="4-blast2go"><a href="#4-blast2go" class="headerlink" title="4. blast2go"></a>4. blast2go</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd data1/data/blast2go/</span><br><span class="line">mysql -u root -p &lt; b2gdb.sql</span><br><span class="line">mysql -u root -p -e &quot;GRANT ALL ON b2gdb.* TO &apos;blast2go&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;blast4it&apos;;&quot;</span><br><span class="line">mysql -u root -p -e &quot;FLUSH PRIVILEGES;&quot;</span><br><span class="line"># 这一步很耗时</span><br><span class="line">nohup time mysql -s -u root -p b2gdb &lt; go_monthly-assocdb-data &gt; mysql.out 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
<p><img src="/images/mysql/time.PNG" alt=""></p>
<h2 id="5-参考"><a href="#5-参考" class="headerlink" title="5. 参考"></a>5. 参考</h2><ul>
<li><a href="http://seanlook.com/2016/04/22/mysql-sql-mode-troubleshooting/" target="_blank" rel="noopener">MySQL sql_mode 说明</a></li>
<li><a href="http://www.bioinfo-scrounger.com/archives/188" target="_blank" rel="noopener">blast2go本地化教程</a></li>
<li><a href="https://stackoverflow.com/questions/43094726/your-password-does-not-satisfy-the-current-policy-requirements" target="_blank" rel="noopener">your password does not satisfy the current policy requirements</a></li>
<li><a href="https://stackoverflow.com/questions/9918062/another-mysqld-server-running-on-port-3306-error" target="_blank" rel="noopener">another mysqld server running on the port 3306</a></li>
<li><a href="https://www.jianshu.com/p/ef58fb333cd6" target="_blank" rel="noopener">Centos7 完全卸载mysql</a></li>
<li><a href="https://www.jianshu.com/p/1dab9a4d0d5f" target="_blank" rel="noopener">CentOS 7 下 MySQL 5.7 的安装与配置</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://qizhengyang2017.github.io/2019/01/28/blast2go/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qizhengyang">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/28/blast2go/" itemprop="url">
                  建立本地nr数据库
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-01-28 13:16:32" itemprop="dateCreated datePublished" datetime="2019-01-28T13:16:32+08:00">2019-01-28</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-03-03 13:17:11" itemprop="dateModified" datetime="2019-03-03T13:17:11+08:00">2019-03-03</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 下载nr数据库，并解压</span><br><span class="line"><span class="meta">#</span> 安装nt/nr库需要进行环境变量配置，在家目录下新建一个.ncbirc配置文件</span><br><span class="line">nohup time update_blastdb.pl --decompress nr &gt; out.log 2&gt;&amp;1 &amp;</span><br><span class="line"><span class="meta">#</span> 同一目录下建立nr_plant子库</span><br><span class="line">blastdb_aliastool -seqidlist sequence.seq -db nr -out nr_plant -title nr_plant</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 运行时间相当长</span><br><span class="line">blastp -query  AT-ARR.fa -db nr -outfmt 11 -out ARR.blastp@nr.asn -num_threads 8</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 测试时间</span><br><span class="line">time blastp -query ~/qizhengyang/AT-ARR.fa -db nr_plant -outfmt 11 -out ARR.blastp@nr.asn -num_threads 8</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://qizhengyang2017.github.io/2019/01/26/服务器安装-CentOS-7-并开启ssh服务之后/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qizhengyang">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/26/服务器安装-CentOS-7-并开启ssh服务之后/" itemprop="url">
                  服务器安装 CentOS 7 并开启ssh服务之后
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-01-26 17:11:40" itemprop="dateCreated datePublished" datetime="2019-01-26T17:11:40+08:00">2019-01-26</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-02-26 17:16:14" itemprop="dateModified" datetime="2019-02-26T17:16:14+08:00">2019-02-26</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>挂载服务器里的另外两块硬盘硬盘</strong></p>
<ol>
<li>查看没有挂载的硬盘 fdisk -l</li>
<li>格式化硬盘，mkfs.ext4 /dev/sdb.报错，/dev/sdb is apparently in use by the system; will not make a 文件系统 here!。用这个命令：dmsetup remove_all</li>
<li>mkfs.ext4 /dev/sdb</li>
<li>挂载 mount /dev/sdb /data</li>
</ol>
<p><strong>mount挂载ntfs 格式的移动硬盘</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">成功执行</span><br><span class="line">mount -t ntfs-3g /dev/sdd1 /run/media/qi/Zhangmiao_15623277907</span><br><span class="line">未成功执行</span><br><span class="line">mount -t ntfs-3g /dev/sdb5 /run/media/qi/软件</span><br></pre></td></tr></table></figure>
<p><strong>自动挂载设置</strong></p>
<blockquote>
<p>Ps:在使用gnome桌面挂载U盘的时候发现，系统可以识别NTFS 分区的存在，但是通过桌面无法自动挂载，系统会提示：</p>
<p>Error mounting /dev/sdb1 at /run/media/lenovo/v220w: Command-line `mount -t “ntfs” -o “uhelper=udisks2,nodev,nosuid,uid=1000,gid=1000,dmask=0077,fmask=0177” “/dev/sdb1” “/run/media/lenovo/v220w”‘ exited with non-zero exit status 32: mount: unknown filesystem type ‘ntfs’</p>
<p>mount 提示未知的文件系统类型 ‘ntfs’</p>
<p>解决办法：</p>
<p>$ mount[Tab][Tab]  #连续按两次 Tab 键作命令补齐</p>
<p>mount             mount.glusterfs   mount.nfs4        mountstats<br>mount.cifs        mount.lowntfs-3g  mount.ntfs-3g<br>mount.fuse        mount.nfs         mountpoint        </p>
<p>可以看到只有mount.ntfs-3g，在使用 mount -t 挂载ntfs 时 mount 会调用 mount.ntfs-3g 而非默认的 mount.ntfs</p>
<p>$ locate mount.ntfs-3g  #查找有关文件所在位置<br>/usr/local/share/man/man8/mount.ntfs-3g.8<br>/usr/sbin/mount.ntfs-3g<br>$ sudo ln -s /usr/sbin/mount.ntfs-3g  /usr/sbin/mount.ntfs   #创建软链接</p>
<p>之后就可以自动识别U 盘而不会出现如上报错了。。。</p>
</blockquote>
<p><strong>centOS7 将“桌面”、“图片”等替换成英文</strong></p>
<ol>
<li>export LANG=en_US</li>
<li>xdg-user-dirs-gtk-update</li>
<li>弹出配置界面，选择替换</li>
<li>export LANG=zh_CN.UTF-8</li>
<li>重启，不替换。</li>
</ol>
<p><strong>IP变化</strong></p>
<p>wlp0s26f7u3:<br>inet 192.168.1.102/24<br>发现只有连同一个wifi(Magic-home)的电脑才能登入。</p>
<p>原来的IP：<br>4: wlp0s26f7u3:<br>inet 10.164.11.166</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://qizhengyang2017.github.io/2018/12/12/exporting-nice-plots-in-r/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qizhengyang">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/12/exporting-nice-plots-in-r/" itemprop="url">
                  R输出图形
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-12-12 17:42:06 / Modified: 18:00:19" itemprop="dateCreated datePublished" datetime="2018-12-12T17:42:06+08:00">2018-12-12</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>这篇博文写的很好 <a href="https://www.r-bloggers.com/exporting-nice-plots-in-r/" target="_blank" rel="noopener">https://www.r-bloggers.com/exporting-nice-plots-in-r/</a><br>介绍的 Inkscape 也很好用，解决了之前IGV输出SVG图片的问题。导入PPT只显示一半。用Ai cc 打开，报错。“往返Tiny时剪贴将丢失”，只有框架没有图</p>
<p>There are two main problems when exporting graphics from R:</p>
<ul>
<li>Anti-aliasing is not activated in Windows R (this does not apply to Linux or Mac) – <strong>windows下没有反锯齿设置</strong>，解决：library(Cairo)</li>
<li>When increasing the resolution the labels automatically decrease and become unreadable  –<strong>分辨率升高，标签会自动缩小</strong></li>
</ul>
<p>If we want to increase the resolution of the plot we can’t just change the resolution parameter:<br>We also have to change the point size, the formula is size * new resolution DPI / 72 DPI:</p>
<p>If we double the image size we also need to double the point size:</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/12/12/exporting-nice-plots-in-r/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://qizhengyang2017.github.io/2018/12/10/Google-News/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qizhengyang">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/10/Google-News/" itemprop="url">
                  Google news "epigenetics plants"
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-12-10 23:14:13 / Modified: 23:16:56" itemprop="dateCreated datePublished" datetime="2018-12-10T23:14:13+08:00">2018-12-10</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>University of Nebraska-Lincoln researchers have found revolutionary evidence that an evolutionary phenomenon at work in complex organisms is at play in their single-celled, extreme-loving counterparts, too.<br><img src="https://www.astrobio.net/wp-content/uploads/2018/12/187441_web.jpg" alt=""></p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://qizhengyang2017.github.io/2018/11/03/集群上安装DESeq2遇到的困难及解决办法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qizhengyang">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/03/集群上安装DESeq2遇到的困难及解决办法/" itemprop="url">
                  集群上安装DESeq2遇到的困难及解决办法
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-11-03 22:18:08" itemprop="dateCreated datePublished" datetime="2018-11-03T22:18:08+08:00">2018-11-03</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-11-04 13:18:12" itemprop="dateModified" datetime="2018-11-04T13:18:12+08:00">2018-11-04</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li><p>BiocManager::install(“DESeq2”, version = “3.8”)<br>报错，错误内容：<br>configure: WARNING: Only g++ version 4.7.2 or greater can be used with RcppArmadillo.<br>configure: error: Please use a different compiler.<br>ERROR: configuration failed for package ‘RcppArmadillo’</p>
</li>
<li><p>源码安装gcc<br><a href="https://blog.csdn.net/swing2008/article/details/63250192" target="_blank" rel="noopener">参考</a><br>../configure –prefix=/home02/qizhengyang/packages -enable-checking=release -enable-languages=c,c++ -disable-multilib<br>报错，错误内容：<br>/usr/bin/ld: cannot find -lgfortran</p>
</li>
<li><p>重新安装gcc，增加fortran<br>../configure –prefix=/home02/qizhengyang/packages -enable-checking=release -enable-languages=c,c++,fortran -disable-multilib &amp;&amp; make -j4 &amp;&amp; make install</p>
</li>
<li><p>添加两个lib<br>export LD_LIBRARY_PATH=$HOME/packages/lib64:$LD_LIBRARY_PATH<br>export LD_LIBRARY_PATH=$HOME/packages/lib:$LD_LIBRARY_PATH</p>
</li>
</ol>
<ol start="5">
<li>BiocManager::install(“DESeq2”, version = “3.8”)<br>成功</li>
</ol>
<p>备注：configure时间超级长。过程艰辛。还尝试过手动安装RcppArmadillo，失败。<br>.libPaths()<br>“/home02/qizhengyang/packages/R/lib64/R/library”<br>R CMD INSTALL -l /home02/qizhengyang/packages/R/lib64/R/library RcppArmadillo_0.3.6.3.tar.gz</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">25</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">17</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 – <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder"></span>

  

  
</div>


  



  <div class="powered-by">Powered by <a class="theme-link" target="_blank" rel="external nofollow" href="https://hexo.io">Hexo</a> v3.7.1</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a class="theme-link" target="_blank" rel="external nofollow" href="https://theme-next.org">NexT.Mist</a> v6.4.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.4.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.4.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.4.0"></script>



  



  










  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  
  

  

  

  

  

  

</body>
</html>
